{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Practical Test\n",
    "\n",
    "© Explore Data Science Academy\n",
    "\n",
    "The NLP practical test will take place within this Jupyter notebook. Each question will require you to write a function which will return the answer. This notebook will be graded automatically, so it is important that the names of any existing variables and functions are left unchanged.\n",
    "\n",
    "A shell function with the correct name for each question has already been defined for you. You will simply need to fill in the necessary code inside the function, as directed by the comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Honour Code\n",
    "\n",
    "I **Cameron**, **Pike**, confirm - by submitting this document - that the solutions in this notebook are a result of my own work and that I abide by the EDSA honour code (https://drive.google.com/file/d/1QDCjGZJ8-FmJE3bZdIQNwnJyQKPhHZBn/view?usp=sharing).\n",
    "\n",
    "Non-compliance with the honour code constitutes a material breach of contract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries and Read In the Data\n",
    "\n",
    "Do not modify or remove any of the code in these cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/bevan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/bevan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "/tmp/ipykernel_11995/2955079538.py:124: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['message'] = [entry.lower() for entry in data['message']]\n",
      "/tmp/ipykernel_11995/2955079538.py:130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_test['message'] = [entry.lower() for entry in data_test['message']]\n",
      "/tmp/ipykernel_11995/2955079538.py:164: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['message'] = data['message'].apply(lambda message: cleaning_stopwords(message))\n",
      "/tmp/ipykernel_11995/2955079538.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_test['message'] = data_test['message'].apply(lambda message: cleaning_stopwords(message))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15819 entries, 0 to 15818\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   sentiment  15819 non-null  int64 \n",
      " 1   message    15819 non-null  object\n",
      " 2   tweetid    15819 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 370.9+ KB\n",
      "Count of columns in the data is:   3\n",
      "Count of rows in the data is:   15819\n",
      "data\n",
      "                                                 message  sentiment\n",
      "0      PolySciMajor EPA chief doesn't think carbon di...          1\n",
      "1      It's not like we lack evidence of anthropogeni...          1\n",
      "2      RT @RawStory: Researchers say we have three ye...          2\n",
      "3      #TodayinMaker# WIRED : 2016 was a pivotal year...          1\n",
      "4      RT @SoyNovioDeTodas: It's 2016, and a racist, ...          1\n",
      "...                                                  ...        ...\n",
      "15814  RT @ezlusztig: They took down the material on ...          1\n",
      "15815  RT @washingtonpost: How climate change could b...          2\n",
      "15816  notiven: RT: nytimesworld :What does Trump act...          0\n",
      "15817  RT @sara8smiles: Hey liberals the climate chan...         -1\n",
      "15818  RT @Chet_Cannon: .@kurteichenwald's 'climate c...          0\n",
      "\n",
      "[15819 rows x 2 columns]\n",
      "data_test\n",
      "                                                 message\n",
      "0      Europe will now be looking to China to make su...\n",
      "1      Combine this with the polling of staffers re c...\n",
      "2      The scary, unimpeachable evidence that climate...\n",
      "3      @Karoli @morgfair @OsborneInk @dailykos \\nPuti...\n",
      "4      RT @FakeWillMoore: 'Female orgasms cause globa...\n",
      "...                                                  ...\n",
      "10541  RT @BrittanyBohrer: Brb, writing a poem about ...\n",
      "10542  2016: the year climate change came home: Durin...\n",
      "10543  RT @loop_vanuatu: Pacific countries positive a...\n",
      "10544  RT @xanria_00018: Youâre so hot, you must be...\n",
      "10545  RT @chloebalaoing: climate change is a global ...\n",
      "\n",
      "[10546 rows x 1 columns]\n",
      "target unique values\n",
      "[ 1  2  0 -1]\n",
      "before stop words\n",
      "15814    rt @ezlusztig: they took down the material on ...\n",
      "15815    rt @washingtonpost: how climate change could b...\n",
      "15816    notiven: rt: nytimesworld :what does trump act...\n",
      "15817    rt @sara8smiles: hey liberals the climate chan...\n",
      "15818    rt @chet_cannon: .@kurteichenwald's 'climate c...\n",
      "Name: message, dtype: object\n",
      "before stop words test data\n",
      "10541    rt @brittanybohrer: brb, writing a poem about ...\n",
      "10542    2016: the year climate change came home: durin...\n",
      "10543    rt @loop_vanuatu: pacific countries positive a...\n",
      "10544    rt @xanria_00018: youâre so hot, you must be...\n",
      "10545    rt @chloebalaoing: climate change is a global ...\n",
      "Name: message, dtype: object\n",
      "after stop words\n",
      "0    polyscimajor epa chief doesn't think carbon di...\n",
      "1    it's not like lack evidence anthropogenic glob...\n",
      "2    rt @rawstory: researchers say three years act ...\n",
      "3    #todayinmaker# wired : 2016 pivotal year war c...\n",
      "4    rt @soynoviodetodas: it's 2016, racist, sexist...\n",
      "Name: message, dtype: object\n",
      "after stop words test data\n",
      "0    europe looking china make sure not alone fight...\n",
      "1    combine polling staffers climate change womens...\n",
      "2    scary, unimpeachable evidence climate change a...\n",
      "3    @karoli @morgfair @osborneink @dailykos putin ...\n",
      "4    rt @fakewillmoore: 'female orgasms cause globa...\n",
      "Name: message, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11995/2955079538.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['message']= data['message'].apply(lambda x: cleaning_punctuations(x))\n",
      "/tmp/ipykernel_11995/2955079538.py:193: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_test['message']= data_test['message'].apply(lambda x: cleaning_punctuations(x))\n",
      "/tmp/ipykernel_11995/2955079538.py:201: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['message'] = data['message'].apply(lambda x: cleaning_repeating_char(x))\n",
      "/tmp/ipykernel_11995/2955079538.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_test['message'] = data_test['message'].apply(lambda x: cleaning_repeating_char(x))\n",
      "/tmp/ipykernel_11995/2955079538.py:213: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['message'] = data['message'].apply(lambda x: cleaning_URLs(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "punctuation\n",
      "15814    rt ezlusztig took material global warming lgbt...\n",
      "15815    rt washingtonpost climate change could breakin...\n",
      "15816    notiven rt nytimesworld what trump actually be...\n",
      "15817    rt sara8smiles hey liberals climate change cra...\n",
      "15818    rt chetcannon kurteichenwalds climate change e...\n",
      "Name: message, dtype: object\n",
      "punctuation test data\n",
      "10541    rt brittanybohrer brb writing poem climate cha...\n",
      "10542    2016 year climate change came home hottest yea...\n",
      "10543    rt loopvanuatu pacific countries positive fiji...\n",
      "10544    rt xanria00018 youâre hot must cause global ...\n",
      "10545    rt chloebalaoing climate change global issue t...\n",
      "Name: message, dtype: object\n",
      "after repeating charss\n",
      "15814    rt ezlusztig took material global warming lgbt...\n",
      "15815    rt washingtonpost climate change could breakin...\n",
      "15816    notiven rt nytimesworld what trump actually be...\n",
      "15817    rt sara8smiles hey liberals climate change cra...\n",
      "15818    rt chetcannon kurteichenwalds climate change e...\n",
      "Name: message, dtype: object\n",
      "after repeating chars test data\n",
      "10541    rt brittanybohrer brb writing poem climate cha...\n",
      "10542    216 year climate change came home hottest year...\n",
      "10543    rt loopvanuatu pacific countries positive fiji...\n",
      "10544    rt xanria0018 youâre hot must cause global w...\n",
      "10545    rt chloebalaoing climate change global issue t...\n",
      "Name: message, dtype: object\n",
      "after clean urls\n",
      "15814    rt ezlusztig took material global warming lgbt...\n",
      "15815    rt washingtonpost climate change could breakin...\n",
      "15816    notiven rt nytimesworld what trump actually be...\n",
      "15817    rt sara8smiles hey liberals climate change cra...\n",
      "15818    rt chetcannon kurteichenwalds climate change e...\n",
      "Name: message, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11995/2955079538.py:217: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_test['message'] = data_test['message'].apply(lambda x: cleaning_URLs(x))\n",
      "/tmp/ipykernel_11995/2955079538.py:224: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['message'] = data['message'].apply(lambda x: cleaning_numbers(x))\n",
      "/tmp/ipykernel_11995/2955079538.py:228: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_test['message'] = data_test['message'].apply(lambda x: cleaning_numbers(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after clean urls test data\n",
      "10541    rt brittanybohrer brb writing poem climate cha...\n",
      "10542    216 year climate change came home hottest year...\n",
      "10543    rt loopvanuatu pacific countries positive fiji...\n",
      "10544    rt xanria0018 youâre hot must cause global w...\n",
      "10545    rt chloebalaoing climate change global issue t...\n",
      "Name: message, dtype: object\n",
      "after clean numbers\n",
      "15814    rt ezlusztig took material global warming lgbt...\n",
      "15815    rt washingtonpost climate change could breakin...\n",
      "15816    notiven rt nytimesworld what trump actually be...\n",
      "15817    rt sarasmiles hey liberals climate change crap...\n",
      "15818    rt chetcannon kurteichenwalds climate change e...\n",
      "Name: message, dtype: object\n",
      "after clean numbers test data\n",
      "10541    rt brittanybohrer brb writing poem climate cha...\n",
      "10542     year climate change came home hottest year re...\n",
      "10543    rt loopvanuatu pacific countries positive fiji...\n",
      "10544    rt xanria youâre hot must cause global warmi...\n",
      "10545    rt chloebalaoing climate change global issue t...\n",
      "Name: message, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11995/2955079538.py:241: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['message']= [word_tokenize(entry) for entry in data['message']]\n",
      "/tmp/ipykernel_11995/2955079538.py:242: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_test['message']= [word_tokenize(entry) for entry in data_test['message']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epa': 1492, 'chief': 737, 'doesnt': 1292, 'think': 4461, 'carbon': 636, 'dioxide': 1229, 'main': 2729, 'cause': 661, 'global': 1867, 'warming': 4794, 'wait': 4783, 'via': 4740, 'mashable': 2786, 'like': 2654, 'lack': 2564, 'evidence': 1542, 'anthropogenic': 233, 'rt': 3857, 'rawstory': 3629, 'researcher': 3752, 'say': 3921, 'three': 4478, 'year': 4964, 'act': 43, 'climate': 792, 'change': 703, 'late': 2584, 'wire': 4890, 'pivotal': 3363, 'war': 4791, 'racist': 3603, 'sexist': 4038, 'deny': 1178, 'bigot': 458, 'lead': 2601, 'poll': 3414, 'electionnight': 1414, 'worth': 4934, 'read': 3637, 'whether': 4856, 'dont': 1302, 'believe': 432, 'thenation': 4438, 'mike': 2863, 'penny': 3302, 'warm': 4792, 'smoking': 4146, 'lung': 2716, 'cancer': 625, 'six': 4110, 'big': 456, 'thing': 4460, 'today': 4504, 'fight': 1680, 'yo': 4975, 'want': 4790, 'die': 1214, 'old': 3157, 'age': 101, 'stephenschlegel': 4246, 'shes': 4056, 'go': 1885, 'husband': 2205, 'hope': 2100, 'people': 3305, 'also': 166, 'power': 3442, 'home': 2088, 'renewable': 3728, 'energy': 1460, 'tveitdal': 4607, 'percent': 3309, 'chance': 701, 'avoid': 352, 'study': 4281, 'find': 1692, 'oh': 3150, 'god': 1887, 'trumps': 4585, 'government': 1903, 'remove': 3726, 'page': 3238, 'website': 4829, 'hour': 2114, 'ahead': 117, 'climatemarch': 808, 'fossil': 1754, 'fuel': 1801, 'giant': 1855, 'exxonmobil': 1601, 'public': 3565, 'harvard': 1999, 'academic': 22, 'conclude': 902, 'glblctzn': 1864, 'wan': 4789, 'na': 2969, 'live': 2669, 'forever': 1746, 'nothing': 3081, 'issue': 2397, 'scrub': 3968, 'civil': 770, 'right': 3816, 'lgbt': 2638, 'patagonia': 3273, 'elect': 1411, 'leader': 2602, 'fail': 1615, 'approach': 270, 'environment': 1485, 'amp': 196, 'serious': 4023, 'worthy': 4935, 'urgency': 4704, 'action': 44, 'sensanders': 4015, 'presidentelect': 3473, 'million': 2877, 'mr': 2945, 'tweet': 4608, 'abt': 20, 'cast': 652, 'see': 3994, 'reply': 3737, 'beg': 423, 'come': 869, 'country': 998, 'back': 363, 'ccities': 671, 'mayor': 2803, 'represent': 3741, 'citizen': 766, 'urge': 4702, 'worldwildlife': 4927, 'impact': 2253, 'wildlife': 4878, 'httpstcooztapcdlk': 2150, 'cop': 970, 'earthtomarrakech': 1370, 'httpstcoxmxgpvhqy': 2172, 'meet': 2816, 'guy': 1963, 'let': 2635, 'truth': 4587, 'gay': 1830, 'exist': 1563, 'scientist': 3950, 'wipe': 4889, 'entire': 1480, 'underwater': 4650, 'ecosystem': 1389, 'obama': 3126, 'raise': 3611, 'well': 4840, 'vote': 4769, 'candidate': 626, 'science': 3940, 'hate': 2006, 'mental': 2831, 'health': 2017, 'pretty': 3482, 'low': 2707, 'menu': 2833, 'hit': 2075, 'food': 1730, 'production': 3513, 'bangladesh': 381, 'confront': 913, 'head': 2015, 'hey': 2051, 'michael': 2848, 'vet': 4739, 'approve': 272, 'strategy': 4268, 'tackle': 4359, 'support': 4318, 'majority': 2734, 'cdns': 674, 'cdnpoli': 673, 'sally': 3891, 'prove': 3555, 'smart': 4138, 'twitchyteam': 4610, 'need': 3010, 'first': 1700, 'understands': 4648, 'congress': 920, 'neiltyson': 3019, 'explain': 1577, 'denounce': 1176, 'choice': 744, 'guide': 1957, 'paris': 3256, 'pact': 3237, 'role': 3845, 'theresistance': 4449, 'latimes': 2586, 'river': 3824, 'could': 990, 'decimate': 1125, 'wild': 4875, 'oyster': 3229, 'san': 3898, 'francisco': 1766, 'bay': 399, 'ignore': 2234, 'basic': 394, 'china': 741, 'trump': 4583, 'lie': 2647, 'berniesanders': 447, 'imvotingbecause': 2265, 'future': 1811, 'planet': 3371, 'stake': 4220, 'hillary': 2064, 'clinton': 817, 'combat': 867, 'donald': 1298, 'independent': 2281, 'team': 4382, 'data': 1093, 'white': 4860, 'house': 2115, 'may': 2801, 'break': 541, 'toxic': 4540, 'soil': 4160, 'vast': 4728, 'waste': 4806, 'water': 4809, 'runaway': 3865, 'part': 3262, 'gas': 1825, 'fracking': 1762, 'america': 187, 'sure': 4325, 'call': 612, 'fit': 1705, 'world': 4921, 'animal': 217, 'deal': 1113, 'simple': 4094, 'policy': 3403, 'complex': 889, 'tone': 4518, 'qanda': 3582, 'protest': 3552, 'help': 2038, 'target': 4372, 'nation': 2987, 'play': 3379, 'long': 2687, 'game': 1820, 'conversationedu': 957, 'thedailybeast': 4429, 'denial': 1171, 'cost': 986, 'trillion': 4572, 'win': 4882, 'probability': 3502, 'bullshit': 584, 'man': 2745, 'saw': 3920, 'final': 1688, 'thats': 4422, 'know': 2545, 'isnt': 2393, 'real': 3642, 'washingtonpost': 4803, 'alaskan': 136, 'tundra': 4598, 'fill': 1685, 'atmosphere': 327, 'worsen': 4932, 'sunlorrie': 4312, 'indian': 2284, 'environmentalist': 1488, 'dicaprio': 1209, 'documentary': 1288, 'realdonaldtrump': 3643, 'tax': 4376, 'globalist': 1873, 'idea': 2223, 'population': 3426, 'whole': 4864, 'reason': 3651, 'propagate': 3541, 'anyone': 247, 'view': 4749, 'non': 3068, 'polluter': 3416, 'please': 3382, 'step': 4243, 'forward': 1753, 'resist': 3760, 'impeach': 2254, 'stevesgoddard': 4252, 'wind': 4883, 'close': 820, 'area': 281, 'afternoon': 99, 'would': 4936, 'blame': 486, 'except': 1555, 'happens': 1988, 'supply': 4317, 'risk': 3823, 'threaten': 4475, 'international': 2354, 'trade': 4543, 'warn': 4797, 'expert': 1576, 'foxnews': 1761, 'macron': 2719, 'charm': 721, 'mind': 2879, 'chris': 749, 'talk': 4365, 'second': 3987, 'executive': 1561, 'order': 3185, 'due': 1342, 'sign': 4084, 'he': 2014, 'president': 3472, 'united': 4667, 'state': 4232, 'fuck': 1795, 'kelkulus': 2509, 'irony': 2382, 'florida': 1721, 'danger': 1083, 'wash': 4801, 'away': 357, 'rise': 3822, 'sea': 3974, 'level': 2637, 'denies': 1175, 'misslizzynj': 2898, 'lmao': 2673, 'complain': 886, 'snowflake': 4152, 'winter': 4888, 'one': 3163, 'arnold': 288, 'vehicle': 4732, 'whine': 4857, 'hows': 2121, 'great': 1919, 'space': 4183, 'save': 3914, 'pollution': 3419, 'india': 2283, 'reach': 3633, 'speed': 4196, 'unep': 4656, 'lay': 2596, 'city': 769, 'body': 506, 'finance': 1690, 'solution': 4164, 'republican': 3744, 'time': 4495, 'hoax': 2079, 'though': 4470, 'kylegriffi': 2558, 'nyt': 3114, 'review': 3795, 'draft': 1315, 'fed': 1658, 'directly': 1236, 'contradict': 946, 'claim': 774, 'antarctica': 231, 'nigga': 3051, 'use': 4712, 'air': 124, 'two': 4613, 'cent': 683, 'political': 3404, 'leadership': 2603, 'era': 1506, 'bbcbreaking': 402, 'uk': 4626, 'agreement': 109, 'comprehensive': 892, 'treaty': 4564, 'tell': 4397, 'invent': 2364, 'business': 592, 'lol': 2683, 'school': 3937, 'motherjones': 2937, 'race': 3600, 'watch': 4808, 'care': 639, 'nsf': 3095, 'ship': 4059, 'primary': 3490, 'arctic': 280, 'freeze': 1776, 'stay': 4238, 'club': 825, 'penguin': 3300, 'shut': 4076, 'economist': 1386, 'incorporate': 2277, 'reality': 3646, 'listen': 2665, 'human': 2188, 'face': 1607, 'disastrous': 1245, 'cernovich': 691, 'question': 3587, 'manmade': 2758, 'doubt': 1307, 'havent': 2010, 'inconvenient': 2276, 'process': 3508, 'occur': 3136, 'naturally': 2995, 'extreme': 1595, 'eventually': 1532, 'severe': 4034, 'drought': 1332, 'neoliberalism': 3021, 'con': 895, 'individual': 2290, 'martin': 2784, 'lukacs': 2713, 'davidsirota': 1101, 'must': 2962, 'rick': 3810, 'perry': 3319, 'texas': 4413, 'kill': 2529, 'bill': 463, 'require': 3747, 'agency': 102, 'prepare': 3464, 'frighten': 1788, 'hot': 2110, 'weve': 4847, 'short': 4065, 'term': 4403, 'work': 4918, 'send': 4010, 'feed': 1660, 'minister': 2884, 'joshfrydenberg': 2465, 'refuse': 3687, 'allow': 160, 'council': 993, 'fact': 1609, 'leonardo': 2629, 'discus': 1252, 'verge': 4734, 'google': 1896, 'timelapse': 4496, 'update': 4693, 'illustrates': 2241, 'sethmacfarlane': 4030, 'hrc': 2123, 'propose': 3546, 'instal': 2325, 'half': 1975, 'billion': 464, 'solar': 4161, 'panel': 3248, 'end': 1455, 'beforetheflood': 421, 'everyone': 1538, 'understand': 4646, 'leodicaprio': 2626, 'ever': 1533, 'rich': 3805, 'colleague': 856, 'create': 1013, 'buzz': 598, 'germany': 1849, 'earthjustice': 1367, 'noaa': 3061, 'report': 3738, 'nd': 3004, 'history': 2074, 'denier': 1174, 'admin': 67, 'conservative': 930, 'love': 2705, 'huh': 2187, 'egg': 1405, 'life': 2648, 'senior': 4013, 'quality': 3583, 'climatechange': 795, 'check': 726, 'event': 1531, 'towards': 4537, 'alleviate': 157, 'poverty': 3441, 'reduce': 3678, 'improve': 2263, 'healthcare': 2018, 'mad': 2720, 'cnn': 831, 'stupid': 4284, 'decide': 1124, 'epidemic': 1496, 'hurt': 2204, 'fisherman': 1703, 'job': 2444, 'another': 227, 'advisor': 81, 'clueless': 827, 'climateprogress': 812, 'environmental': 1486, 'contribute': 949, 'director': 1237, 'coal': 839, 'lobby': 2677, 'deputy': 1185, 'chinese': 742, 'massive': 2790, 'iceberg': 2216, 'thinkprogress': 4464, 'rex': 3802, 'email': 1431, 'doctor': 1285, 'agree': 108, 'make': 2736, 'sick': 4079, 'earthday': 1363, 'marchforscience': 2768, 'vice': 4742, 'ghg': 1852, 'methane': 2841, 'substantial': 4290, 'snow': 4150, 'march': 2767, 'greenharvard': 1926, 'uniquely': 4665, 'important': 2261, 'battle': 398, 'look': 2691, 'officially': 3148, 'sorry': 4176, 'everybody': 1536, 'else': 1429, 'popsci': 3424, 'ten': 4400, 'ugly': 4624, 'potus': 3440, 'idiot': 2226, 'im': 2243, 'college': 859, 'paper': 3250, 'someone': 4168, 'pls': 3386, 'natgeochannel': 2985, 'travels': 4562, 'httpstcolkdehjtnn': 2140, 'peta': 3327, 'meat': 2812, 'deforestation': 1143, 'extinction': 1591, 'advocate': 84, 'prisonplanet': 3498, 'wow': 4939, 'finally': 1689, 'evil': 1544, 'wake': 4784, 'good': 1893, 'article': 295, 'decision': 1126, 'form': 1749, 'nytnational': 3119, 'budget': 578, 'proposal': 3545, 'spend': 4198, 'money': 2920, 'anymore': 246, 'tomilahren': 4513, 'kinda': 2534, 'funny': 1809, 'professor': 3519, 'shit': 4062, 'show': 4071, 'literally': 2667, 'kloppholic': 2541, 'imagine': 2246, 'try': 4590, 'convince': 961, 'instead': 2328, 'conspiracy': 935, 'every': 1535, 'major': 2733, 'scientific': 3948, 'organization': 3191, 'dems': 1170, 'stfu': 4253, 'signordal': 4088, 'new': 3029, 'terrible': 4406, 'news': 3032, 'alarmist': 133, 'plant': 3376, 'follow': 1729, 'hear': 2021, 'digital': 1222, 'polar': 3399, 'bear': 411, 'extinct': 1590, 'land': 2572, 'death': 1116, 'expect': 1570, 'labour': 2563, 'punch': 3571, 'killer': 2530, 'stop': 4260, 'stupidity': 4285, 'reader': 3638, 'theory': 4440, 'way': 4815, 'avert': 350, 'apply': 264, 'method': 2842, 'foxandfriends': 1760, 'priest': 3488, 'preach': 3452, 'sasjabeslik': 3909, 'ecological': 1382, 'migrant': 2860, 'displaced': 1266, 'abandon': 2, 'ft': 1794, 'rescue': 3750, 'chocolate': 743, 'europe': 1528, 'loud': 2701, 'youre': 4980, 'degree': 1149, 'early': 1361, 'november': 3088, 'los': 2695, 'angeles': 213, 'accord': 33, 'youth': 4981, 'almost': 162, 'pop': 3422, 'best': 448, 'line': 2660, 'defense': 1138, 'security': 3993, 'richardmunang': 3809, 'cbsnews': 669, 'get': 1850, 'single': 4103, 'inc': 2269, 'fake': 1621, 'nasa': 2980, 'research': 3751, 'estate': 1522, 'market': 2775, 'start': 4230, 'charliedaniels': 719, 'worry': 4930, 'terrify': 4407, 'video': 4746, 'koch': 2549, 'brother': 568, 'heritage': 2046, 'vp': 4777, 'ask': 306, 'tree': 4565, 'grow': 1941, 'crime': 1021, 'rate': 3625, 'effect': 1399, 'physorgcom': 3352, 'astrokatie': 323, 'several': 4033, 'without': 4900, 'charge': 714, 'withhold': 4898, 'information': 2304, 'tillerson': 4491, 'decline': 1129, 'answer': 228, 'kamalaharris': 2495, 'stand': 4223, 'jerrybrowngov': 2432, 'california': 611, 'httpstcoxpyesmyx': 2173, 'consider': 933, 'piece': 3356, 'column': 865, 'steve': 4249, 'inform': 2303, 'ppl': 3445, 'specie': 4191, 'habitat': 1967, 'already': 165, 'either': 1409, 'loss': 2698, 'quiz': 3596, 'cultural': 1048, 'still': 4256, 'interesting': 2350, 'natural': 2994, 'render': 3727, 'earth': 1362, 'uninhabitable': 4662, 'who': 4862, 'town': 4539, 'thank': 4417, 'enjoy': 1471, 'quick': 3589, 'trip': 4573, 'brown': 570, 'county': 999, 'park': 3260, 'day': 1104, 'apocalypse': 254, 'famine': 1628, 'perpetrate': 3317, 'safetypindaily': 3887, 'federal': 1659, 'department': 1180, 'censor': 681, 'reveal': 3790, 'olliemilman': 3158, 'billnye': 469, 'link': 2661, 'journal': 2468, 'guess': 1955, 'ivanka': 2403, 'reporter': 3739, 'insight': 2319, 'woman': 4907, 'columnist': 866, 'ny': 3107, 'debut': 1121, 'fox': 1759, 'pakistan': 3240, 'th': 4416, 'vulnerable': 4780, 'whats': 4853, 'experience': 1574, 'prime': 3491, 'indyusa': 2295, 'knock': 2543, 'brexit': 551, 'bury': 590, 'really': 3649, 'drop': 1331, 'dead': 1110, 'nobel': 3063, 'ignorance': 2232, 'shock': 4063, 'trudeau': 4579, 'put': 3579, 'defence': 1135, 'nationalpost': 2990, 'carbongate': 638, 'physicist': 3351, 'co': 837, 'respond': 3767, 'lastweektonight': 2583, 'silly': 4091, 'give': 1859, 'resource': 3764, 'thehill': 4436, 'rahm': 3607, 'emanuel': 1433, 'post': 3434, 'webpage': 4828, 'delete': 1154, 'administration': 68, 'jackposobiec': 2409, 'soon': 4173, 'deanofcomedy': 1114, 'closely': 821, 'wall': 4788, 'street': 4270, 'sd': 3971, 'take': 4363, 'urgent': 4705, 'join': 2454, 'juddlegum': 2475, 'kid': 2527, 'stuff': 4282, 'energydesk': 1461, 'historic': 2072, 'fall': 1623, 'profound': 3523, 'effort': 1403, 'bad': 366, 'billmckibben': 467, 'misinformation': 2892, 'elizkolbert': 1424, 'newyorker': 3039, 'exxonknew': 1600, 'pablorodas': 3232, 'west': 4843, 'coast': 841, 'even': 1530, 'ecointernet': 1381, 'secretary': 3989, 'stephen': 4244, 'hawk': 2012, 'message': 2837, 'iconic': 2219, 'beach': 410, 'vanish': 4726, 'thanks': 4419, 'mrdenmore': 2946, 'apart': 253, 'recession': 3659, 'double': 1306, 'pariah': 3255, 'refugee': 3686, 'cook': 964, 'book': 513, 'presentation': 3469, 'easy': 1374, 'daily': 1071, 'eat': 1375, 'beef': 419, 'here': 2044, 'catastrophe': 654, 'wreak': 4940, 'havoc': 2011, 'argue': 284, 'countermoonbat': 997, 'predict': 3456, 'manhattan': 2752, 'concern': 900, 'brace': 529, 'bitterly': 480, 'cold': 852, 'shift': 4057, 'vortex': 4768, 'httpstcotkrnpzlix': 2159, 'senatormroberts': 4008, 'much': 2950, 'none': 3070, 'economy': 1387, 'httpstcoewvqtit': 2132, 'httpstcoqvrfztte': 2151, 'cant': 627, 'number': 3101, 'priority': 3496, 'scottadamssays': 3958, 'choose': 746, 'ag': 100, 'govt': 1905, 'plan': 3369, 'address': 62, 'inspiration': 2322, 'em': 1430, 'exxon': 1599, 'shareholder': 4049, 'move': 2941, 'force': 1740, 'company': 883, 'disclose': 1247, 'pose': 3429, 'far': 1634, 'doomsday': 1304, 'solve': 4165, 'problem': 3505, 'fix': 1707, 'sit': 4108, 'natureorg': 3000, 'reaffirm': 3640, 'commitment': 874, 'parisagreement': 3258, 'jacobwhitesides': 2411, 'christmas': 758, 'httpstcovvazjvxhw': 2164, 'john': 2447, 'miss': 2896, 'voice': 4765, 'zealand': 4992, 'herald': 2042, 'anything': 248, 'admit': 71, 'decade': 1122, 'ago': 107, 'huffpostpol': 2184, 'alicebell': 148, 'itll': 2400, 'feel': 1663, 'tomorrow': 4515, 'context': 943, 'key': 2522, 'protect': 3549, 'boost': 515, 'funding': 1808, 'develop': 1203, 'adapt': 59, 'paulhbeckwith': 3283, 'folk': 1728, 'story': 4265, 'oceans': 3138, 'acid': 39, 'huffingtonpost': 2181, 'cmdangelo': 828, 'businessinsider': 593, 'apple': 263, 'bradydennis': 532, 'cdc': 672, 'abruptly': 15, 'cancel': 624, 'longplanned': 2689, 'conference': 907, 'contest': 942, 'fakenews': 1622, 'canada': 620, 'turn': 4601, 'ditch': 1275, 'open': 3171, 'myth': 2967, 'maga': 2722, 'especially': 1517, 'pull': 3569, 'reverse': 3794, 'petraau': 3332, 'least': 2609, 'evolution': 1545, 'thedailyclimate': 4430, 'escape': 1514, 'timesofindia': 4497, 'campaigner': 618, 'snorkel': 4149, 'greatbarrierreef': 1920, 'plus': 3387, 'side': 4080, 'karena': 2502, 'climatechangrr': 798, 'bonn': 511, 'conversation': 956, 'morning': 2930, 'arthur': 294, 'yes': 4970, 'obviously': 3135, 'natgeophotos': 2986, 'although': 171, 'scary': 3932, 'topic': 4524, 'ice': 2215, 'everyones': 1539, 'something': 4169, 'progressive': 3528, 'hero': 2047, 'kick': 2526, 'select': 4000, 'include': 2271, 'un': 4633, 'cnvey': 836, 'bother': 521, 'washtimes': 4804, 'whistleblower': 4859, 'allege': 154, 'manipulate': 2754, 'hide': 2055, 'pause': 3286, 'alias': 147, 'emails': 1432, 'politician': 3407, 'fart': 1639, 'brilliant': 558, 'cartoon': 648, 'sum': 4305, 'barackobama': 385, 'jamespeshaw': 2416, 'nzgreens': 3125, 'clean': 780, 'adamcurry': 57, 'al': 130, 'agenda': 103, 'info': 2302, 'uniocracy': 4663, 'theyll': 4454, 'theyre': 4455, 'opchemtrails': 3169, 'turtle': 4605, 'around': 290, 'pace': 3233, 'existential': 1565, 'board': 502, 'bounce': 523, 'interested': 2349, 'httpstcoltvcrfhf': 2141, 'todd': 4505, 'npr': 3093, 'nonsense': 3073, 'blow': 499, 'guardianeco': 1951, 'barrier': 390, 'reef': 3680, 'leave': 2610, 'scream': 3965, 'wsj': 4945, 'rebuke': 3654, 'ge': 1833, 'ceo': 689, 'point': 3394, 'men': 2829, 'speak': 4186, 'pollutingpruitt': 3418, 'continue': 944, 'climatefacts': 802, 'schwarzenegger': 3938, 'yayitsrob': 4960, 'moderate': 2913, 'extremely': 1596, 'radical': 3604, 'curb': 1052, 'outpace': 3209, 'citiesclimate': 765, 'climatehome': 807, 'week': 4832, 'guardian': 1948, 'multiple': 2951, 'shape': 4047, 'concept': 898, 'manufacture': 2761, 'noncompetitive': 3069, 'office': 3146, 'ban': 378, 'phrase': 3348, 'nuclear': 3098, 'slowly': 4136, 'cbs': 668, 'skeptic': 4114, 'wonder': 4911, 'sue': 4296, 'disease': 1255, 'outside': 3212, 'fear': 1655, 'consequence': 927, 'victory': 4745, 'agent': 104, 'benefit': 440, 'weak': 4817, 'name': 2971, 'proud': 3554, 'creative': 1017, 'palmerreport': 3246, 'nodapl': 3065, 'golden': 1890, 'gate': 1827, 'badlands': 369, 'national': 2988, 'defy': 1146, 'ocean': 3137, 'never': 3028, 'nye': 3111, 'success': 4291, 'fusion': 1810, 'become': 415, 'discuss': 1253, 'pic': 3353, 'alone': 163, 'probably': 3503, 'accelerate': 25, 'night': 3053, 'scott': 3957, 'pruitt': 3560, 'fool': 1732, 'yacht': 4953, 'hypocrite': 2209, 'yet': 4972, 'inaction': 2267, 'opponent': 3174, 'rtfollowernodad': 3859, 'parent': 3253, 'id': 2221, 'child': 738, 'stave': 4237, 'obamas': 3129, 'legacy': 2617, 'weaken': 4818, 'investment': 2368, 'dirty': 1238, 'voxdotcom': 4775, 'election': 1413, 'mark': 2771, 'limit': 2658, 'httpstcocjiupxdiy': 2125, 'moron': 2932, 'ff': 1673, 'corrupt': 984, 'contributor': 952, 'pick': 3354, 'sceptic': 3935, 'rapid': 3622, 'melt': 2822, 'laugh': 2588, 'vicenews': 4743, 'rumor': 3863, 'mattis': 2798, 'iansomerhalder': 2214, 'changetonight': 708, 'episode': 1497, 'yearsofliving': 4966, 'per': 3308, 'sad': 3882, 'suggest': 4299, 'engadget': 1463, 'ddlovato': 1108, 'ivotedbecause': 2406, 'equality': 1499, 'immigration': 2251, 'reform': 3685, 'prochoice': 3509, 'sell': 4003, 'control': 953, 'everything': 1540, 'magnitude': 2726, 'strike': 4272, 'renewables': 3729, 'climatehaw': 806, 'shell': 4054, 'profit': 3521, 'sallykohn': 3892, 'related': 3705, 'large': 2577, 'pattern': 3279, 'affect': 88, 'joshgad': 2466, 'mourn': 2939, 'stage': 4217, 'standup': 4225, 'globalgoals': 1870, 'crucial': 1037, 'achieve': 38, 'senfeinstein': 4012, 'senate': 4005, 'committee': 876, 'restore': 3772, 'vital': 4762, 'epascottpruitt': 1494, 'drive': 1326, 'copy': 972, 'dummy': 1346, 'ajplus': 128, 'top': 4523, 'summit': 4308, 'affirm': 90, 'theyd': 4453, 'green': 1923, 'sleep': 4131, 'rain': 3608, 'bring': 559, 'glacier': 1861, 'yr': 4985, 'position': 3430, 'regional': 3693, 'model': 2912, 'crazy': 1011, 'blizzard': 493, 'campaign': 617, 'persuade': 3324, 'teacher': 4381, 'debatable': 1117, 'york': 4976, 'hire': 2069, 'previously': 3486, 'write': 4942, 'arab': 275, 'urged': 4703, 'bbcnews': 403, 'party': 3268, 'commit': 873, 'effective': 1400, 'nytimes': 3116, 'suffer': 4297, 'equally': 1500, 'cba': 665, 'case': 649, 'court': 1002, 'pope': 3423, 'challenge': 699, 'upset': 4698, 'significant': 4087, 'weather': 4823, 'course': 1001, 'press': 3478, 'train': 4550, 'spread': 4210, 'awareness': 356, 'black': 483, 'hitler': 2076, 'holocaust': 2085, 'gon': 1892, 'bc': 407, 'focus': 1725, 'putin': 3580, 'cc': 670, 'climaterealists': 813, 'democrat': 1166, 'young': 4979, 'drill': 1323, 'morocco': 2931, 'slow': 4135, 'butt': 596, 'mother': 2935, 'nature': 2996, 'amcp': 185, 'isolate': 2394, 'completely': 888, 'track': 4541, 'record': 3667, 'ok': 3153, 'colour': 864, 'last': 2582, 'sierraclub': 4083, 'announce': 222, 'ambitious': 184, 'achievable': 37, 'cut': 1060, 'adambandt': 56, 'sealevel': 3976, 'local': 2679, 'joshfoxfilm': 2464, 'absurd': 19, 'tornado': 4525, 'hurricane': 2201, 'etc': 1524, 'result': 3774, 'wrong': 4944, 'person': 3320, 'clearly': 789, 'share': 4048, 'economic': 1383, 'davos': 1103, 'wef': 4835, 'humancaused': 2189, 'rerouted': 3749, 'bbc': 401, 'okay': 3154, 'participate': 3263, 'group': 1940, 'mediterranean': 2814, 'youtube': 4983, 'sun': 4310, 'scramble': 3963, 'appolitics': 268, 'service': 4026, 'defies': 1141, 'social': 4156, 'medium': 2815, 'intern': 2352, 'trigger': 4571, 'front': 1789, 'flood': 1718, 'plague': 3368, 'quote': 3597, 'letter': 2636, 'editor': 1394, 'connect': 922, 'star': 4228, 'less': 2632, 'thought': 4471, 'fund': 1805, 'gst': 1944, 'road': 3826, 'forest': 1745, 'little': 2668, 'zone': 4999, 'might': 2859, 'wont': 4913, 'sarahksilverman': 3906, 'ur': 4700, 'oil': 3152, 'realize': 3647, 'response': 3768, 'communicate': 879, 'official': 3147, 'genuinely': 1840, 'curious': 1054, 'visit': 4759, 'agriculture': 110, 'victim': 4744, 'mention': 2832, 'joint': 2455, 'statement': 4234, 'cleanenergy': 783, 'pay': 3288, 'cash': 650, 'promote': 3536, 'montreal': 2924, 'stance': 4222, 'natgeo': 2984, 'projection': 3531, 'russian': 3870, 'cloud': 823, 'sky': 4123, 'nsw': 3096, 'law': 2591, 'liberal': 2643, 'download': 1311, 'mzjacobson': 2968, 'enable': 1451, 'starve': 4231, 'possibly': 3433, 'httpstcoogwwskw': 2148, 'tulsigabbard': 4597, 'illustrate': 2240, 'communities': 881, 'argument': 285, 'dana': 1082, 'nuccitelli': 3097, 'harvey': 2003, 'threat': 4474, 'word': 4916, 'across': 42, 'direction': 1234, 'temperature': 4399, 'sunday': 4311, 'void': 4766, 'la': 2559, 'wfp': 4848, 'increase': 2278, 'insecurity': 2315, 'mine': 2880, 'relevant': 3709, 'insane': 2314, 'learn': 2608, 'difference': 1218, 'justintrudeau': 2490, 'welcome': 4839, 'together': 4508, 'harmful': 1995, 'unnecessary': 4676, 'car': 635, 'osmanakkoca': 3198, 'declare': 1128, 'turkey': 4600, 'financial': 1691, 'system': 4355, 'heatwaves': 2030, 'seven': 4032, 'hotspot': 2111, 'interactive': 2347, 'map': 2764, 'web': 4827, 'site': 4109, 'attack': 329, 'emission': 1439, 'accept': 26, 'consensus': 926, 'often': 3149, 'dismiss': 1263, 'fruit': 1792, 'flower': 1723, 'neighbour': 3017, 'thinks': 4465, 'summary': 4306, 'billionaire': 465, 'guardiannews': 1952, 'explore': 1581, 'alaska': 135, 'regardless': 3690, 'italy': 2399, 'pledge': 3383, 'democracynow': 1165, 'chomsky': 745, 'happen': 1987, 'shouldnt': 4068, 'chunkymark': 760, 'true': 4580, 'supporter': 4319, 'supremacist': 4322, 'xenophobic': 4949, 'reindeer': 3702, 'repeal': 3733, 'obamacare': 3127, 'dismantle': 1262, 'common': 877, 'sense': 4016, 'chicago': 736, 'epas': 1493, 'slate': 4128, 'wine': 4885, 'industry': 2294, 'trouble': 4577, 'ty': 4614, 'five': 1706, 'pacific': 3234, 'island': 2391, 'lose': 2696, 'defiantly': 1140, 'despite': 1194, 'nasaclimate': 2981, 'lift': 2652, 'arent': 282, 'enough': 1475, 'peru': 3325, 'recent': 3657, 'tuckercarlson': 4595, 'forget': 1747, 'explode': 1580, 'orleans': 3195, 'kenya': 2516, 'logic': 2682, 'many': 2763, 'brave': 537, 'denver': 1177, 'demand': 1163, 'inspire': 2323, 'ezralevant': 1606, 'videos': 4747, 'marrakech': 2779, 'greenpeace': 1931, 'coral': 973, 'joke': 2456, 'society': 4159, 'extends': 1587, 'ap': 252, 'uproar': 4697, 'contradicts': 947, 'washington': 4802, 'influencers': 2301, 'supremacy': 4323, 'vaccine': 4721, 'initiatives': 2310, 'australia': 341, 'behind': 427, 'momentum': 2918, 'didnt': 1212, 'ultravlolence': 4630, 'interviewer': 2359, 'melania': 2821, 'hello': 2037, 'kind': 2533, 'strong': 4274, 'cover': 1003, 'mask': 2787, 'programme': 3526, 'adaptation': 60, 'skip': 4122, 'bos': 518, 'honestly': 2094, 'dumb': 1343, 'hell': 2036, 'backwards': 365, 'shameful': 4046, 'remember': 3720, 'mislead': 2893, 'enters': 1479, 'huge': 2186, 'vegan': 4731, 'police': 3402, 'equivalent': 1505, 'creationism': 1015, 'bunch': 586, 'oxford': 3228, 'elitists': 1422, 'poor': 3421, 'range': 3615, 'different': 1219, 'africa': 96, 'hr': 2122, 'jedrlee': 2427, 'girl': 1858, 'nowthisnews': 3091, 'hiatus': 2053, 'celebrate': 678, 'overcome': 3217, 'theecoheroes': 4434, 'dineshdsouza': 1224, 'gender': 1834, 'maybe': 2802, 'facts': 1612, 'fingerprint': 1696, 'miami': 2846, 'sunny': 4313, 'mexico': 2843, 'worse': 4931, 'becketadams': 414, 'twitter': 4611, 'seem': 3998, 'angry': 216, 'bret': 550, 'oped': 3170, 'private': 3499, 'investor': 2369, 'reign': 3700, 'memo': 2827, 'alarm': 131, 'staff': 4215, 'cnbc': 829, 'pennsylvania': 3301, 'clash': 777, 'frankieboyle': 1769, 'bright': 557, 'humanity': 2193, 'fascist': 1641, 'amyaharder': 198, 'chriscmooney': 750, 'project': 3530, 'marine': 2770, 'reserve': 3753, 'cope': 971, 'since': 4098, 'christ': 756, 'return': 3782, 'attorney': 335, 'general': 1836, 'japan': 2423, 'faith': 1620, 'unite': 4666, 'exit': 1567, 'humanitarian': 2192, 'crisis': 1025, 'rose': 3852, 'odd': 3142, 'mess': 2836, 'cycle': 1064, 'deluge': 1159, 'caller': 613, 'regard': 3689, 'ajenglish': 127, 'colony': 860, 'httpstcoibmsbissbx': 2136, 'undo': 4652, 'progress': 3527, 'davidcorndc': 1099, 'nice': 3047, 'everglades': 1534, 'youve': 4984, 'nobody': 3064, 'active': 45, 'meeting': 2818, 'urges': 4707, 'high': 2056, 'afp': 94, 'yall': 4958, 'idk': 2229, 'jackthela': 2410, 'warrior': 4800, 'naomi': 2974, 'auspol': 339, 'george': 1845, 'exists': 1566, 'disappear': 1241, 'hillaryclinton': 2065, 'cool': 965, 'place': 3367, 'humid': 2196, 'thot': 4469, 'mood': 2925, 'therell': 4445, 'conflict': 912, 'limited': 2659, 'truly': 4582, 'aide': 121, 'mass': 2788, 'north': 3076, 'tank': 4368, 'httpstconzcxrxrhu': 2147, 'boys': 528, 'protection': 3550, 'wwfuk': 4948, 'earthhour': 1365, 'joyannreid': 2472, 'next': 3040, 'four': 1758, 'set': 4028, 'education': 1397, 'fun': 1804, 'markbutlermp': 2772, 'greenpeaceuk': 1932, 'usa': 4709, 'nbc': 3002, 'mic': 2847, 'mammal': 2743, 'terrorism': 4409, 'prediction': 3458, 'groundhog': 1939, 'ohio': 3151, 'trend': 4567, 'toward': 4536, 'acceptance': 27, 'flat': 1711, 'rude': 3860, 'honest': 2093, 'assaadrazzouk': 310, 'lecture': 2611, 'importance': 2260, 'cooperation': 969, 'barack': 384, 'anonypress': 226, 'leak': 2606, 'block': 495, 'coffee': 848, 'knowledge': 2546, 'recognize': 3664, 'disgrace': 1257, 'jeopardize': 2430, 'cathmckenna': 658, 'debate': 1118, 'expensive': 1573, 'totally': 4530, 'presidential': 3475, 'feature': 1656, 'whatsoever': 4854, 'climatecentral': 794, 'cabinet': 604, 'nominee': 3067, 'da': 1069, 'thinker': 4462, 'ordered': 3186, 'hand': 1982, 'tillersons': 4492, 'secret': 3988, 'prosecutor': 3548, 'smartnews': 4140, 'spring': 4211, 'culprit': 1046, 'gore': 1898, 'dispatch': 1265, 'highlight': 2059, 'repstevensmith': 3743, 'host': 2109, 'politickels': 3409, 'build': 581, 'currently': 1056, 'swear': 4340, 'oxfam': 3227, 'ep': 1491, 'ensure': 1477, 'actually': 53, 'markruffalo': 2778, 'depress': 1182, 'recordbreaking': 3668, 'push': 3577, 'film': 1686, 'emerge': 1437, 'firm': 1699, 'author': 344, 'radio': 3605, 'realdonaldtrumps': 3644, 'dangerous': 1084, 'malcolm': 2739, 'robert': 3829, 'sb': 3922, 'alvinlindsay': 177, 'weird': 4838, 'lib': 2642, 'dare': 1088, 'scientistseu': 3951, 'antiscience': 240, 'seriously': 4024, 'storm': 4264, 'as': 298, 'fraud': 1772, 'launch': 2590, 'innovation': 2311, 'heres': 2045, 'stanford': 4227, 'usfreedomarmy': 4715, 'enlist': 1472, 'gt': 1946, 'cnni': 833, 'implication': 2257, 'canadian': 622, 'bob': 504, 'fellow': 1666, 'paul': 3280, 'joseph': 2462, 'watson': 4811, 'silent': 4090, 'april': 273, 'yeah': 4963, 'greenpeaceusa': 1933, 'image': 2244, 'freezing': 1777, 'keep': 2507, 'heard': 2022, 'johniadarola': 2450, 'islamic': 2390, 'simulate': 4096, 'modern': 2914, 'dust': 1352, 'bowl': 525, 'anthrax': 232, 'alive': 152, 'permafrost': 3316, 'enter': 1478, 'promise': 3535, 'destroy': 1195, 'halt': 1978, 'mishacollins': 2891, 'chairman': 698, 'dcexaminer': 1106, 'weatherman': 4826, 'base': 393, 'plot': 3385, 'dt': 1339, 'sanction': 3899, 'damn': 1080, 'phannam': 3335, 'disaster': 1244, 'alley': 158, 'test': 4411, 'military': 2873, 'smh': 4142, 'stigabell': 4255, 'red': 3672, 'capitalweather': 633, 'standard': 4224, 'central': 685, 'icymi': 2220, 'feedly': 1662, 'cf': 694, 'journalist': 2470, 'propagandist': 3540, 'required': 3748, 'alter': 168, 'globalwarming': 1877, 'roll': 3846, 'source': 4179, 'reuters': 3786, 'enemy': 1459, 'hrkbenowen': 2124, 'horror': 2107, 'chelsea': 731, 'diabetes': 1208, 'hard': 1990, 'involve': 2372, 'sector': 3991, 'african': 97, 'london': 2685, 'quartz': 3585, 'scienceclimate': 3942, 'teach': 4380, 'program': 3525, 'gavinnewsom': 1829, 'list': 2664, 'brain': 534, 'concerned': 901, 'citizens': 767, 'dicaprios': 1210, 'fantastic': 1632, 'free': 1774, 'mistake': 2899, 'spirit': 4203, 'dr': 1314, 'add': 61, 'publish': 3568, 'ko': 2547, 'punishment': 3573, 'barely': 389, 'colbert': 851, 'mock': 2910, 'idiotic': 2227, 'comment': 871, 'movement': 2942, 'bernie': 446, 'bible': 454, 'safe': 3884, 'heck': 2033, 'grist': 1937, 'fresh': 1781, 'desert': 1189, 'davidaxelrod': 1098, 'uae': 4619, 'confirm': 909, 'run': 3864, 'dramatically': 1318, 'broad': 564, 'implement': 2256, 'codinghorror': 847, 'factor': 1610, 'kindly': 2536, 'nytimesbusiness': 3117, 'engineering': 1467, 'wreck': 4941, 'proof': 3537, 'extinctsymbol': 1592, 'dupe': 1351, 'mcm': 2806, 'ca': 603, 'sail': 3889, 'weapon': 4821, 'bloomberg': 498, 'catch': 656, 'character': 713, 'weekend': 4833, 'spiritualsmoker': 4204, 'absolutely': 17, 'disgust': 1258, 'coalition': 840, 'withdrawal': 4897, 'pr': 3446, 'excellent': 1554, 'rest': 3771, 'powerful': 3443, 'khayhoe': 2525, 'actonclimate': 49, 'administrator': 69, 'speech': 4195, 'delegate': 1152, 'harvardbiz': 2000, 'possible': 3432, 'collapse': 855, 'presidency': 3471, 'realjameswoods': 3648, 'productive': 3514, 'housing': 2117, 'eu': 1527, 'tory': 4528, 'full': 1802, 'ericboehlert': 1508, 'reminder': 3723, 'network': 3027, 'newscast': 3033, 'min': 2878, 'wolf': 4906, 'unfold': 4660, 'astound': 322, 'assumption': 319, 'ground': 1938, 'singleissue': 4104, 'voter': 4771, 'ranger': 3617, 'fighting': 1681, 'monster': 2922, 'biden': 455, 'abcnews': 5, 'sweep': 4345, 'rollback': 3847, 'obamaera': 3128, 'rule': 3862, 'bout': 524, 'ruin': 3861, 'danrather': 1086, 'slash': 4127, 'prevent': 3483, 'mean': 2809, 'reject': 3703, 'attempt': 330, 'summer': 4307, 'heat': 2025, 'mikebloomberg': 2864, 'leodicaprios': 2627, 'tonight': 4519, 'le': 2600, 'di': 1207, 'il': 2237, 'ta': 4357, 'sweeping': 4346, 'american': 188, 'politics': 3411, 'conscious': 925, 'nurture': 3102, 'sustainability': 4336, 'physic': 3349, 'father': 1646, 'phd': 3336, 'pretend': 3480, 'climateaction': 793, 'internet': 2355, 'iot': 2374, 'presidentelecttrump': 3474, 'lovely': 2706, 'insurance': 2335, 'republicans': 3745, 'retire': 3778, 'sinces': 4100, 'nygovcuomo': 3112, 'aggressively': 106, 'meanwhile': 2810, 'income': 2272, 'inequality': 2296, 'snap': 4147, 'location': 2680, 'type': 4616, 'skeptical': 4115, 'controversial': 954, 'doc': 1284, 'kurteichenwald': 2554, 'conservs': 932, 'pretending': 3481, 'color': 861, 'abortion': 12, 'favourite': 1653, 'bbanimals': 400, 'seat': 3984, 'bank': 382, 'bbcqt': 404, 'businessman': 594, 'associate': 317, 'lot': 2699, 'rocket': 3838, 'prize': 3500, 'scale': 3923, 'petition': 3331, 'scottish': 3959, 'golf': 1891, 'cite': 764, 'altnatparkser': 172, 'employee': 1446, 'factual': 1613, 'revise': 3796, 'moment': 2917, 'michaelemann': 2849, 'suit': 4304, 'trial': 4568, 'theeconomist': 4435, 'wmo': 4903, 'beautiful': 413, 'february': 1657, 'fiction': 1675, 'kerry': 2518, 'remain': 3716, 'involved': 2373, 'seanspicier': 3979, 'regs': 3695, 'altusepa': 176, 'lengthy': 2623, 'defend': 1136, 'always': 178, 'theres': 4446, 'rip': 3821, 'nytnickc': 3120, 'michigan': 2851, 'crowd': 1036, 'falsely': 1626, 'spin': 4202, 'climategate': 803, 'skepticism': 4116, 'goal': 1886, 'fanatic': 1631, 'lord': 2694, 'lawson': 2593, 'dallasnews': 1077, 'resolution': 3762, 'psa': 3562, 'dairy': 1075, 'cali': 610, 'endless': 1457, 'foot': 1734, 'external': 1589, 'hmm': 2078, 'buzzfeednews': 599, 'endanger': 1456, 'reference': 3683, 'inauguration': 2268, 'arguably': 283, 'deeply': 1131, 'hall': 1976, 'resistance': 3761, 'popular': 3425, 'belief': 430, 'tv': 4606, 'hasnt': 2004, 'nasas': 2982, 'invisible': 2370, 'pin': 3357, 'hop': 2099, 'kp': 2553, 'gov': 1899, 'fire': 1698, 'nz': 3124, 'guardianus': 1954, 'irinnews': 2379, 'do': 1283, 'regular': 3696, 'donaldtrump': 1299, 'fyi': 1813, 'anxiety': 245, 'midnight': 2856, 'goodbye': 1894, 'algae': 144, 'basically': 395, 'document': 1287, 'egypt': 1406, 'nine': 3058, 'bloom': 497, 'arabian': 277, 'tie': 4489, 'beneath': 439, 'fish': 1702, 'community': 882, 'tap': 4370, 'handle': 1984, 'dude': 1341, 'triple': 4574, 'initiative': 2309, 'pipeline': 3359, 'chain': 696, 'tool': 4521, 'abraham': 13, 'wetland': 4846, 'resilience': 3757, 'indigenous': 2289, 'transform': 4553, 'hospital': 2108, 'infrastructure': 2306, 'vermont': 4736, 'boston': 519, 'globe': 1879, 'there': 4443, 'complete': 887, 'analysis': 201, 'globally': 1876, 'spot': 4207, 'contribution': 951, 'cbcnews': 667, 'socalled': 4155, 'peak': 3294, 'availability': 347, 'doe': 1291, 'annual': 225, 'founder': 1757, 'wed': 4831, 'earlier': 1360, 'atlantic': 326, 'usled': 4716, 'santa': 3902, 'extra': 1593, 'marshall': 2783, 'islander': 2392, 'unlikely': 4675, 'ally': 161, 'simply': 4095, 'living': 2670, 'womenclimate': 4908, 'opinion': 3173, 'pen': 3298, 'critic': 1026, 'channel': 710, 'blast': 487, 'value': 4723, 'mitigate': 2902, 'hence': 2041, 'finding': 1693, 'dad': 1070, 'compromise': 893, 'false': 1625, 'equivalence': 1504, 'critical': 1027, 'recover': 3669, 'calm': 614, 'adequate': 63, 'sciam': 3939, 'suggests': 4301, 'americans': 189, 'algore': 146, 'educate': 1396, 'planetary': 3372, 'sarahkendzior': 3905, 'womens': 4909, 'grill': 1935, 'russia': 3869, 'confirmation': 910, 'worldfnature': 4922, 'dept': 1184, 'request': 3746, 'worker': 4919, 'worried': 4929, 'ukipnfkn': 4628, 'hat': 2005, 'nhs': 3045, 'tower': 4538, 'lit': 2666, 'honor': 2096, 'france': 1764, 'buy': 597, 'balk': 376, 'stark': 4229, 'unchecked': 4638, 'profitable': 3522, 'opportunity': 3175, 'aiannucci': 119, 'elected': 1412, 'didntso': 1213, 'eg': 1404, 'special': 4190, 'instrument': 2332, 'changerelated': 707, 'series': 4022, 'allenwest': 156, 'bless': 491, 'heart': 2024, 'wade': 4781, 'instantly': 2327, 'foeus': 1727, 'actively': 46, 'wired': 4891, 'accuse': 36, 'boat': 503, 'belugasolar': 437, 'attitude': 334, 'taxpayer': 4377, 'vie': 4748, 'shuts': 4077, 'stain': 4219, 'senatormenendez': 4007, 'retweet': 3783, 'representative': 3742, 'willing': 4881, 'rap': 3620, 'wtf': 4946, 'criminal': 1022, 'note': 3080, 'commonwealth': 878, 'damage': 1079, 'adopt': 73, 'glass': 1863, 'omg': 3162, 'freak': 1773, 'conservatives': 931, 'signal': 4085, 'greenhouse': 1927, 'clear': 787, 'premier': 3461, 'kevin': 2521, 'senator': 4006, 'leohickman': 2628, 'theresa': 4447, 'mays': 2804, 'defender': 1137, 'design': 1191, 'crook': 1034, 'crap': 1009, 'scare': 3930, 'andor': 206, 'boo': 512, 'bye': 602, 'attention': 333, 'interest': 2348, 'receive': 3656, 'spectatorindex': 4194, 'section': 3990, 'unless': 4673, 'stopadani': 4261, 'bleach': 488, 'anemone': 209, 'crack': 1008, 'chose': 748, 'sander': 3901, 'personal': 3321, 'julianburnside': 2481, 'turnbullmalcolm': 4603, 'tip': 4499, 'ericholthaus': 1509, 'politicize': 3408, 'climatechangeisreal': 796, 'bet': 449, 'lady': 2565, 'liberty': 2645, 'cry': 1039, 'failure': 1617, 'resilient': 3759, 'bridge': 555, 'indicate': 2286, 'humanmade': 2195, 'anger': 214, 'insult': 2334, 'glad': 1862, 'middle': 2854, 'pentagon': 3303, 'photographer': 3346, 'unparalleled': 4677, 'americas': 190, 'jealous': 2426, 'east': 1372, 'temp': 4398, 'wish': 4894, 'brookingsinst': 566, 'hateful': 2007, 'tho': 4468, 'johnkerry': 2451, 'cofounder': 849, 'activity': 48, 'socialism': 4157, 'yep': 4969, 'climateofhope': 811, 'harsh': 1998, 'overall': 3216, 'growth': 1942, 'equal': 1498, 'subscription': 4288, 'satellite': 3910, 'richardbranson': 3807, 'truck': 4578, 'mining': 2883, 'teenvogue': 4393, 'paulinehansonoz': 3284, 'otherwise': 3200, 'hearing': 2023, 'throw': 4480, 'window': 4884, 'rightwing': 3818, 'latin': 2587, 'climatologist': 816, 'dangerously': 1085, 'album': 139, 'skynewsaust': 4124, 'billshortenmp': 470, 'gaga': 1816, 'artist': 297, 'blackrock': 485, 'manage': 2746, 'frontline': 1790, 'fishing': 1704, 'village': 4751, 'globalwarning': 1878, 'gop': 1897, 'wasnt': 4805, 'economics': 1385, 'unfccc': 4659, 'buhari': 580, 'tropical': 4576, 'alyssamilano': 179, 'scam': 3924, 'log': 2681, 'jonriley': 2460, 'freedom': 1775, 'pollute': 3415, 'assume': 318, 'alarmists': 134, 'religion': 3712, 'sarcasticrover': 3908, 'preserve': 3470, 'indiewire': 2288, 'french': 1778, 'worlds': 4925, 'abbott': 3, 'turnbull': 4602, 'fashion': 1642, 'cyprus': 1068, 'cable': 605, 'spent': 4200, 'southern': 4182, 'delay': 1151, 'httpstcodabchx': 2129, 'climatedepot': 800, 'horrible': 2104, 'theblaze': 4426, 'male': 2741, 'admits': 72, 'blog': 496, 'environmentalism': 1487, 'hairline': 1974, 'democratic': 1167, 'lawmaker': 2592, 'organize': 3192, 'ben': 438, 'jerry': 2431, 'rely': 3715, 'rather': 3626, 'assess': 313, 'burn': 588, 'adviser': 80, 'sen': 4004, 'tan': 4366, 'tear': 4384, 'beyond': 452, 'realmuckmaker': 3650, 'monday': 2919, 'scar': 3927, 'wide': 4871, 'punish': 3572, 'reacts': 3636, 'ignorant': 2233, 'surprising': 4329, 'former': 1750, 'safely': 3885, 'divide': 1277, 'dozen': 1313, 'nonprofit': 3072, 'employ': 1445, 'thousand': 4472, 'lisabloom': 2663, 'knew': 2542, 'aim': 122, 'arm': 286, 'mf': 2845, 'mankind': 2757, 'irresponsible': 2385, 'envdefensefund': 1483, 'asset': 315, 'telegraph': 4394, 'wave': 4814, 'carolina': 645, 'dnr': 1282, 'sink': 4106, 'current': 1055, 'likely': 2656, 'incredible': 2280, 'produce': 3511, 'exactly': 1550, 'elliegoulding': 1425, 'song': 4172, 'jet': 2435, 'ja': 2407, 'beat': 412, 'asapscience': 300, 'nitrogen': 3059, 'element': 1417, 'oregon': 3187, 'eastern': 1373, 'ghostpanther': 1854, 'regulation': 3698, 'diplomacy': 1230, 'account': 34, 'marriage': 2781, 'aligns': 151, 'heavily': 2031, 'positive': 3431, 'dramatic': 1317, 'style': 4286, 'berlin': 445, 'seanhannity': 3977, 'touch': 4531, 'massachusetts': 2789, 'tiny': 4498, 'rally': 3612, 'abc': 4, 'normal': 3075, 'react': 3634, 'cautiously': 663, 'expansion': 1569, 'geoengineering': 1841, 'spray': 4209, 'lots': 2700, 'quickly': 3590, 'diplomat': 1231, 'httpstcowzvbmk': 2167, 'easily': 1371, 'refute': 3688, 'csg': 1040, 'minute': 2888, 'debt': 1119, 'liberalresist': 2644, 'pbs': 3292, 'newshour': 3036, 'en': 1450, 'fine': 1694, 'huffpostscience': 2185, 'de': 1109, 'haveigotnews': 2009, 'announces': 223, 'counter': 995, 'ireland': 2377, 'draw': 1320, 'ive': 2405, 'felt': 1667, 'lesbian': 2631, 'mailonline': 2728, 'pump': 3570, 'nilimajumder': 3057, 'cooperate': 968, 'foreign': 1743, 'robertkennedyjr': 3830, 'cream': 1012, 'mmflint': 2906, 'civiljustus': 773, 'httpstcohypyswhvvv': 2135, 'wage': 4782, 'libs': 2646, 'begs': 425, 'differ': 1217, 'app': 258, 'precious': 3453, 'breathe': 545, 'quit': 3593, 'industrial': 2293, 'intend': 2343, 'accurate': 35, 'mattyglesias': 2799, 'perhaps': 3313, 'rogue': 3841, 'theâ': 4457, 'largescale': 2579, 'corporate': 980, 'farming': 1638, 'changeâ': 709, 'gagtweets': 1817, 'workshop': 4920, 'racism': 3602, 'relate': 3704, 'whistle': 4858, 'blower': 500, 'bit': 477, 'samsteinhp': 3897, 'fwiw': 1812, 'deadly': 1112, 'naomiaklein': 2975, 'bipartisan': 474, 'affair': 87, 'carry': 647, 'foreignpolicy': 1744, 'shoutout': 4070, 'drvox': 1337, 'century': 688, 'glorious': 1880, 'later': 2585, 'beijing': 428, 'embassy': 1435, 'resigns': 3756, 'funder': 1807, 'karen': 2501, 'handel': 1983, 'football': 1736, 'near': 3006, 'particularly': 3264, 'tanzania': 4369, 'version': 4737, 'invite': 2371, 'fiji': 1683, 'nuttall': 3104, 'class': 778, 'homophobic': 2092, 'antiabortion': 235, 'simultaneously': 4097, 'wayne': 4816, 'tracker': 4542, 'seek': 3996, 'pm': 3390, 'pressure': 3479, 'cave': 664, 'yahoonews': 4956, 'activist': 47, 'whatever': 4852, 'richarddawkins': 3808, 'illegal': 2239, 'measure': 2811, 'postbrexit': 3435, 'smoke': 4145, 'electric': 1415, 'russias': 3872, 'sciencepolitics': 3946, 'underscore': 4645, 'cnnpolitics': 835, 'pathetic': 3275, 'sound': 4178, 'aka': 129, 'ya': 4952, 'han': 1981, 'rosling': 3853, 'dy': 1357, 'owillis': 3225, 'denialism': 1172, 'climatenexus': 809, 'vox': 4774, 'rural': 3866, 'prince': 3492, 'charles': 717, 'row': 3856, 'pure': 3575, 'caught': 660, 'suppose': 4320, 'profile': 3520, 'londonbridge': 2686, 'realise': 3645, 'loudobbs': 2702, 'unstoppable': 4687, 'httpstcoxiqyyvn': 2170, 'yahoocanada': 4955, 'afford': 91, 'ourrevolution': 3202, 'impossible': 2262, 'deleted': 1155, 'politico': 3410, 'trail': 4548, 'bird': 475, 'past': 3272, 'johnfugelsang': 2449, 'prof': 3516, 'httpstcomcas': 2142, 'door': 1305, 'bully': 585, 'student': 4280, 'loan': 2676, 'minimum': 2882, 'isi': 2387, 'farmer': 1637, 'farm': 1636, 'align': 150, 'friendsoscience': 1787, 'bostonglobe': 520, 'crop': 1035, 'innovative': 2312, 'govts': 1906, 'making': 2738, 'dismisses': 1264, 'advisory': 82, 'wattsupwiththat': 4813, 'brief': 556, 'thedemocrats': 4433, 'light': 2653, 'rabihalameddine': 3599, 'uncontrollable': 4639, 'rare': 3624, 'criticizes': 1031, 'httpstcoxmqumahdx': 2171, 'httpstconaygjkp': 2145, 'pizza': 3366, 'responsible': 3770, 'denialist': 1173, 'technology': 4387, 'smarter': 4139, 'msnbc': 2948, 'climateofgavin': 810, 'gif': 1856, 'taehyung': 4361, 'scottpruittok': 3961, 'umm': 4632, 'zachjcarter': 4989, 'timcanova': 4494, 'tremendous': 4566, 'geological': 1844, 'struggle': 4278, 'audience': 338, 'practice': 3448, 'usda': 4711, 'uks': 4629, 'mitchellvii': 2901, 'respect': 3766, 'begin': 424, 'roguenasa': 3843, 'observe': 3132, 'gene': 1835, 'mp': 2944, 'extent': 1588, 'anjakolibri': 219, 'negative': 3012, 'outweigh': 3215, 'donate': 1300, 'feeling': 1664, 'gsmeeton': 1943, 'matt': 2795, 'ridley': 3814, 'microsoft': 2852, 'capitalism': 632, 'devos': 1205, 'poison': 3397, 'gun': 1959, 'surprise': 4328, 'irreversible': 2386, 'criticise': 1028, 'boris': 517, 'johnson': 2453, 'repadamschiff': 3731, 'walk': 4786, 'sake': 3890, 'generation': 1838, 'manipulation': 2756, 'shipsandports': 4060, 'thick': 4458, 'language': 2576, 'phoenix': 3342, 'amount': 195, 'sculpture': 3970, 'elizabethmay': 1423, 'noam': 3062, 'safety': 3886, 'religious': 3713, 'cult': 1047, 'depression': 1183, 'ptsd': 3563, 'david': 1097, 'overpopulation': 3220, 'aid': 120, 'earthhouruk': 1366, 'antoniodelotero': 243, 'exaggerate': 1551, 'shout': 4069, 'month': 2923, 'condition': 905, 'haha': 1970, 'mobil': 2908, 'rockefeller': 3837, 'peatlands': 3295, 'center': 684, 'total': 4529, 'httpstcoxagubzf': 2168, 'httpstcozyfexknqno': 2177, 'successful': 4292, 'qz': 3598, 'discussion': 1254, 'beliefs': 431, 'settle': 4031, 'ill': 2238, 'speaks': 4189, 'sentence': 4018, 'integrity': 2340, 'friend': 1784, 'myronebell': 2965, 'ebell': 1377, 'brucebartlett': 571, 'recovery': 3670, 'development': 1204, 'rage': 3606, 'sex': 4036, 'traffic': 4546, 'junkscience': 2485, 'attribute': 336, 'viable': 4741, 'hack': 1968, 'lesson': 2634, 'lkraus': 2672, 'nikki': 3056, 'plz': 3389, 'piss': 3360, 'zero': 4994, 'yesterday': 4971, 'january': 2422, 'tengop': 4401, 'nope': 3074, 'visualization': 4761, 'rebleber': 3653, 'pacificstand': 3235, 'wildfire': 4877, 'asheville': 301, 'orbit': 3184, 'camera': 615, 'monitor': 2921, 'partisan': 3265, 'mission': 2897, 'tom': 4512, 'price': 3487, 'rbreich': 3630, 'citizensclimate': 768, 'south': 4180, 'mcspocky': 2808, 'nytscience': 3123, 'conservation': 928, 'syrian': 4354, 'period': 3315, 'random': 3614, 'magic': 2725, 'appear': 261, 'immediate': 2247, 'outline': 3208, 'twittermoments': 4612, 'narendramodi': 2977, 'dear': 1115, 'sir': 4107, 'appeal': 260, 'advice': 78, 'headline': 2016, 'breitbart': 547, 'standupforscience': 4226, 'bottle': 522, 'plastic': 3377, 'binge': 471, 'coastal': 842, 'reveals': 3791, 'upside': 4699, 'disprove': 1268, 'irrelevant': 2384, 'tuesday': 4596, 'gut': 1961, 'toronto': 4526, 'appropriate': 271, 'culture': 1049, 'interview': 2358, 'websites': 4830, 'icebergs': 2217, 'reddit': 3673, 'bbcworld': 405, 'visible': 4758, 'comic': 870, 'reflect': 3684, 'nrdc': 3094, 'odds': 3143, 'establish': 1521, 'match': 2791, 'despair': 1192, 'hysteria': 2213, 'rampant': 3613, 'example': 1553, 'suggestion': 4300, 'champion': 700, 'ivankatrump': 2404, 'family': 1627, 'platform': 3378, 'depend': 1181, 'lessen': 2633, 'balance': 374, 'leading': 2604, 'attend': 332, 'prepares': 3465, 'ed': 1391, 'retreat': 3780, 'biodiversity': 472, 'phenology': 3337, 'dam': 1078, 'youll': 4978, 'bjornlomborg': 482, 'longterm': 2690, 'civilization': 772, 'statedept': 4233, 'seth': 4029, 'meyers': 2844, 'huffpostcomedy': 2182, 'httpstcoubqxlmrf': 2162, 'access': 29, 'lawsuit': 2594, 'offer': 3145, 'luck': 2711, 'driven': 1327, 'eliminate': 1419, 'fucking': 1800, 'betray': 450, 'essential': 1520, 'detail': 1198, 'survey': 4331, 'perception': 3311, 'aspect': 308, 'jim': 2440, 'hansen': 1986, 'jamilsmith': 2418, 'withdraw': 4896, 'coralmdavenport': 974, 'warmer': 4793, 'mild': 2870, 'highlyanne': 2061, 'fascinate': 1640, 'justice': 2487, 'globalization': 1875, 'braininvading': 535, 'worm': 4928, 'adriennelaf': 74, 'socialist': 4158, 'greed': 1922, 'wealth': 4819, 'chelseaclinton': 732, 'mom': 2916, 'pole': 3401, 'australian': 342, 'woefully': 4905, 'unprepared': 4679, 'jillirobi': 2439, 'brag': 533, 'rape': 3621, 'kkk': 2539, 'notmypresident': 3085, 'grade': 1908, 'congressman': 921, 'trust': 4586, 'coopah': 967, 'salon': 3893, 'cooling': 966, 'acknowledge': 40, 'denying': 1179, 'favorite': 1651, 'zach': 4988, 'dncleak': 1281, 'snob': 4148, 'httpstcosoxskdim': 2156, 'negotiation': 3015, 'flight': 1714, 'theyve': 4456, 'arrive': 291, 'mail': 2727, 'hirokotabuchi': 2071, 'route': 3855, 'unusually': 4690, 'frank': 1767, 'lolgop': 2684, 'interior': 2351, 'elon': 1426, 'investigate': 2366, 'adjust': 65, 'footprint': 1738, 'hypocrisy': 2208, 'hes': 2049, 'carbonbrief': 637, 'october': 3139, 'jordanchariton': 2461, 'reckless': 3661, 'outbreak': 3204, 'seiclimate': 3999, 'norway': 3078, 'colorado': 862, 'reversal': 3793, 'typical': 4617, 'narrative': 2979, 'cybersygh': 1063, 'release': 3708, 'roguesnradvisor': 3844, 'pres': 3467, 'connectivity': 924, 'miel': 2858, 'compel': 885, 'organic': 3190, 'manure': 2762, 'store': 4263, 'outdoors': 3206, 'emit': 1440, 'potential': 3439, 'devastate': 1201, 'inevitable': 2297, 'disappointing': 1243, 'bomb': 510, 'af': 86, 'layer': 2597, 'wear': 4822, 'scandal': 3926, 'fiddle': 1677, 'climatescam': 815, 'tcot': 4379, 'shelf': 4053, 'grab': 1907, 'dinosaur': 1226, 'journey': 2471, 'ucsusa': 4622, 'management': 2747, 'proceeds': 3507, 'mattbors': 2796, 'invest': 2365, 'gap': 1822, 'brutality': 573, 'vladimir': 4764, 'scotland': 3956, 'along': 164, 'overlook': 3219, 'nyc': 3108, 'eriksolheim': 1510, 'undeniable': 4642, 'faster': 1645, 'antonioguterres': 244, 'heathermorristv': 2027, 'outsider': 3213, 'httpstcoznreizogeg': 2176, 'blkahn': 494, 'footage': 1735, 'iucn': 2402, 'saveourocean': 3916, 'intensity': 2346, 'frequency': 1779, 'minority': 2887, 'swing': 4347, 'antarctic': 230, 'friends': 1786, 'thx': 4486, 'net': 3023, 'reaction': 3635, 'whitehouse': 4861, 'dc': 1105, 'inhofe': 2308, 'extremist': 1598, 'taylor': 4378, 'fault': 1647, 'ignores': 2236, 'eats': 1376, 'sixth': 4111, 'sheriffclarke': 4055, 'antacid': 229, 'relieve': 3711, 'happy': 1989, 'ready': 3639, 'analyze': 202, 'be': 409, 'tycoon': 4615, 'retweeted': 3784, 'matter': 2797, 'scienmag': 3947, 'survive': 4333, 'caribbean': 641, 'julessu': 2479, 'youd': 4977, 'alberta': 138, 'ontario': 3165, 'jan': 2420, 'sequel': 4021, 'luxury': 2717, 'busy': 595, 'brianklaas': 554, 'stein': 4241, 'existence': 1564, 'dark': 1090, 'octopus': 3140, 'garage': 1823, 'canary': 623, 'whose': 4866, 'remind': 3722, 'rachaelswindon': 3601, 'corbyn': 975, 'slam': 4125, 'usatoday': 4710, 'asia': 303, 'alexsteffen': 141, 'difficult': 1220, 'animation': 218, 'chrisconsiders': 751, 'third': 4467, 'el': 1410, 'savage': 3913, 'maize': 2732, 'taught': 4375, 'energyenviro': 1462, 'marsh': 2782, 'favour': 1652, 'eye': 1603, 'deserve': 1190, 'ignored': 2235, 'perspective': 3323, 'christian': 757, 'carney': 644, 'defeating': 1134, 'code': 846, 'personally': 3322, 'autism': 346, 'gtgt': 1947, 'favor': 1650, 'robinince': 3832, 'drag': 1316, 'alt': 167, 'hankgreen': 1985, 'indus': 2292, 'valley': 4722, 'idiots': 2228, 'bigots': 461, 'pray': 3450, 'halloween': 1977, 'novel': 3087, 'catastrophic': 655, 'yield': 4974, 'moana': 2907, 'movie': 2943, 'cnnbrk': 832, 'judge': 2476, 'probe': 3504, 'poster': 3436, 'amid': 191, 'rightrelevance': 3817, 'httpstcocyqqufku': 2128, 'guardianaus': 1949, 'centre': 686, 'vulnerability': 4779, 'cuba': 1045, 'irrefutable': 2383, 'hold': 2081, 'conversationus': 959, 'newday': 3030, 'chriscuomo': 752, 'payer': 3289, 'chat': 724, 'insideclimate': 2317, 'overwhelming': 3223, 'ambassador': 183, 'rank': 3618, 'vancouver': 4725, 'considers': 934, 'motherboard': 2936, 'thread': 4473, 'emergency': 1438, 'harper': 1996, 'percentage': 3310, 'optimistic': 3181, 'sacrifice': 3881, 'fast': 1643, 'techreview': 4388, 'buck': 576, 'terrorist': 4410, 'cia': 762, 'dem': 1162, 'bleaching': 489, 'graphic': 1913, 'influence': 2300, 'grim': 1936, 'endorse': 1458, 'openly': 3172, 'sexual': 4039, 'assault': 311, 'orange': 3183, 'round': 3854, 'mixed': 2904, 'perpetuate': 3318, 'destruction': 1196, 'deep': 1130, 'staffer': 4216, 'bold': 509, 'conservationorg': 929, 'vatican': 4729, 'university': 4670, 'internal': 2353, 'publicly': 3567, 'downplay': 1312, 'leopard': 2630, 'properly': 3543, 'ilo': 2242, 'online': 3164, 'harvardchansph': 2001, 'ketanj': 2520, 'spending': 4199, 'celebpacked': 677, 'engage': 1464, 'miracle': 2890, 'unknown': 4671, 'np': 3092, 'richard': 3806, 'bitch': 478, 'parisclimatedeal': 3259, 'fastcompany': 1644, 'stun': 4283, 'photo': 3345, 'chart': 722, 'guardiansustbiz': 1953, 'aint': 123, 'bunk': 587, 'dailykos': 1074, 'hillarys': 2066, 'ha': 1965, 'horrify': 2106, 'necessary': 3009, 'celebrity': 679, 'refer': 3682, 'profbriancox': 3517, 'earthers': 1364, 'bannon': 383, 'jew': 2436, 'session': 4027, 'imply': 2258, 'showthelove': 4073, 'theccoalition': 4428, 'indicator': 2287, 'eh': 1407, 'neil': 3018, 'degrasse': 1148, 'tyson': 4618, 'chrisjzullo': 753, 'breitbarts': 549, 'malta': 2742, 'mikeljollett': 2867, 'therefore': 4444, 'desperate': 1193, 'optimism': 3180, 'hunger': 2198, 'mar': 2765, 'aditya': 64, 'bahadur': 373, 'legislation': 2619, 'dup': 1349, 'couldnt': 991, 'unlike': 4674, 'european': 1529, 'greenerscotland': 1925, 'ewerickson': 1547, 'getup': 1851, 'scifi': 3952, 'longer': 2688, 'hill': 2063, 'picture': 3355, 'rvawonk': 3873, 'behavior': 426, 'drinking': 1325, 'merkel': 2835, 'esp': 1516, 'sciencenews': 3945, 'player': 3380, 'cleantech': 785, 'oppose': 3176, 'dupdeal': 1350, 'lnp': 2674, 'electricity': 1416, 'hamilton': 1979, 'assessment': 314, 'region': 3692, 'direct': 1233, 'scottwalker': 3962, 'stock': 4258, 'chrislhayes': 754, 'absolute': 16, 'perfect': 3312, 'naretevduorp': 2978, 'mural': 2953, 'chill': 740, 'treat': 4563, 'uncertainty': 4637, 'intelligent': 2342, 'lawyer': 2595, 'invasive': 2363, 'carolinelucas': 646, 'colossal': 863, 'productivity': 3515, 'greenhousenyt': 1928, 'deliver': 1157, 'exclusive': 1559, 'unexpected': 4658, 'caitrionambalfe': 606, 'minutelong': 2889, 'symphony': 4352, 'mid': 2853, 'junk': 2484, 'kwill': 2557, 'overwhelm': 3222, 'certainly': 693, 'cleanpowerplan': 784, 'savetheepa': 3917, 'swingdist': 4348, 'voted': 4770, 'badastronomer': 368, 'supermoon': 4316, 'flooding': 1719, 'amaze': 180, 'israel': 2395, 'gain': 1818, 'davidpapp': 1100, 'unique': 4664, 'identify': 2224, 'lifeaseva': 2649, 'shower': 4072, 'reusable': 3785, 'aol': 251, 'jonathanchait': 2459, 'minor': 2886, 'footnote': 1737, 'doom': 1303, 'ladybird': 2566, 'believing': 434, 'warns': 4799, 'httpstcoigsxjgwf': 2137, 'unwomen': 4692, 'adverse': 77, 'peter': 3328, 'nazis': 3001, 'us': 4708, 'army': 287, 'bell': 435, 'jump': 2482, 'tune': 4599, 'peace': 3293, 'empty': 1449, 'chair': 697, 'anchor': 204, 'pro': 3501, 'globalisation': 1872, 'repeat': 3734, 'tomwellborn': 4516, 'phone': 3343, 'feedback': 1661, 'fb': 1654, 'rewrote': 3801, 'nvisser': 3105, 'scene': 3934, 'destructive': 1197, 'bush': 591, 'jr': 2473, 'ah': 116, 'archive': 279, 'dna': 1279, 'dakota': 1076, 'constantly': 936, 'inch': 2270, 'nut': 3103, 'bias': 453, 'billmoyershq': 468, 'shrink': 4075, 'stevenwhirsch': 4251, 'fl': 1708, 'dollar': 1295, 'saturday': 3911, 'stepstoreverseclimatechange': 4247, 'covered': 1005, 'james': 2415, 'truefactsstated': 4581, 'bang': 380, 'afraid': 95, 'explores': 1582, 'oklahoma': 3155, 'suing': 4303, 'surely': 4326, 'purge': 3576, 'editorial': 1395, 'correct': 982, 'neither': 3020, 'ad': 54, 'screen': 3966, 'suspect': 4334, 'seattle': 3985, 'zinke': 4997, 'surround': 4330, 'enormously': 1474, 'postpone': 3438, 'zaibatsunews': 4990, 'ctl': 1043, 'climatereality': 814, 'dog': 1293, 'nasmaraj': 2983, 'murder': 2954, 'nationalism': 2989, 'fucked': 1796, 'fan': 1630, 'december': 1123, 'extend': 1586, 'leahrboss': 2605, 'left': 2614, 'meltdown': 2823, 'redsteeze': 3676, 'shoot': 4064, 'asteroid': 320, 'hole': 2082, 'swallow': 4338, 'benmekler': 441, 'midnovember': 2857, 'quest': 3586, 'capture': 634, 'milestone': 2872, 'hi': 2052, 'trap': 4559, 'cow': 1007, 'greatest': 1921, 'charliekir': 720, 'however': 2120, 'mountain': 2938, 'notice': 3082, 'math': 2794, 'makada': 2735, 'mikehudema': 2865, 'coastline': 843, 'erode': 1511, 'rd': 3632, 'likeagirlinc': 2655, 'lobbyist': 2678, 'seed': 3995, 'proceed': 3506, 'reconsider': 3666, 'rethink': 3777, 'driver': 1328, 'instability': 2324, 'straight': 4266, 'ate': 324, 'ddale': 1107, 'scifri': 3953, 'xhnews': 4950, 'nationwide': 2991, 'scheme': 3936, 'cynical': 1067, 'melting': 2824, 'able': 9, 'bag': 372, 'appoint': 265, 'insurer': 2336, 'count': 994, 'penalty': 3299, 'bettemidler': 451, 'httpstcofmmovzun': 2133, 'flow': 1722, 'iran': 2376, 'vow': 4773, 'core': 977, 'dump': 1347, 'clarity': 776, 'mt': 2949, 'load': 2675, 'presidenttrump': 3476, 'ring': 3819, 'thru': 4481, 'flag': 1709, 'pol': 3398, 'cap': 629, 'mccarthy': 2805, 'drove': 1333, 'coat': 844, 'frame': 1763, 'ezraklein': 1605, 'uh': 4625, 'basis': 396, 'travel': 4561, 'nearly': 3007, 'friendly': 1785, 'greenland': 1929, 'si': 4078, 'encyclical': 1454, 'bigotry': 460, 'homophobia': 2091, 'mainstream': 2730, 'wordpressdotcom': 4917, 'violence': 4753, 'seal': 3975, 'hunt': 2200, 'appreciate': 269, 'adani': 58, 'backlash': 364, 'mitigation': 2903, 'exposure': 1584, 'disregard': 1270, 'previous': 3485, 'bs': 574, 'skill': 4120, 'resident': 3754, 'room': 3850, 'sustain': 4335, 'korea': 2552, 'kuwait': 2556, 'guardiancities': 1950, 'recognise': 3663, 'hotter': 2112, 'apocalyptic': 255, 'tech': 4385, 'boingboing': 508, 'scared': 3931, 'markdistef': 2773, 'tim': 4493, 'ball': 377, 'thwart': 4485, 'unprecedented': 4678, 'ought': 3201, 'millennials': 2876, 'boomer': 514, 'factory': 1611, 'among': 193, 'creation': 1014, 'empower': 1448, 'female': 1668, 'stuck': 4279, 'theresamay': 4448, 'boy': 526, 'exchange': 1557, 'jonathan': 2458, 'toews': 4507, 'rant': 3619, 'gift': 1857, 'computer': 894, 'smash': 4141, 'congratulation': 919, 'investigation': 2367, 'allegedly': 155, 'int': 2337, 'cute': 1061, 'jill': 2438, 'uwm': 4720, 'beforeyouvote': 422, 'httpstcoubmubjmbkv': 2161, 'geographic': 1842, 'encourage': 1453, 'small': 4137, 'mystery': 2966, 'hippie': 2068, 'barefoot': 388, 'ratify': 3628, 'amendment': 186, 'baby': 362, 'screw': 3967, 'channelnews': 711, 'honour': 2097, 'bcpoli': 408, 'anti': 234, 'unable': 4634, 'tribune': 4569, 'hombre': 2087, 'mmfa': 2905, 'nike': 3055, 'hundred': 2197, 'volcano': 4767, 'voting': 4772, 'mercury': 2834, 'daughter': 1095, 'dailyclimate': 1073, 'examine': 1552, 'visualise': 4760, 'breathtaking': 546, 'aggressive': 105, 'legal': 2618, 'avg': 351, 'specific': 4192, 'stall': 4221, 'debunk': 1120, 'manmademoon': 2759, 'orthodox': 3196, 'patriarch': 3276, 'bartholomew': 392, 'delivers': 1158, 'strongest': 4276, 'discover': 1250, 'verify': 4735, 'lower': 2708, 'amazing': 181, 'spell': 4197, 'marklevinshow': 2777, 'hilarious': 2062, 'xi': 4951, 'inside': 2316, 'prolife': 3532, 'miner': 2881, 'anyway': 249, 'oman': 3159, 'clue': 826, 'sfgate': 4040, 'wi': 4869, 'scrubs': 3969, 'disproportionately': 1267, 'affected': 89, 'beloved': 436, 'farage': 1635, 'fri': 1782, 'available': 348, 'understanding': 4647, 'defeat': 1133, 'netflix': 3024, 'regulate': 3697, 'prevention': 3484, 'incoming': 2273, 'unsg': 4685, 'dtrump': 1340, 'ted': 4389, 'houston': 2118, 'file': 1684, 'nycmayor': 3109, 'neighborhood': 3016, 'nicholas': 3048, 'stern': 4248, 'dwnews': 1356, 'wing': 4886, 'politifact': 3412, 'self': 4001, 'gm': 1882, 'pesticide': 3326, 'dig': 1221, 'inhabitat': 2307, 'remote': 3724, 'tangible': 4367, 'landscape': 2574, 'metaphor': 2838, 'bro': 563, 'suck': 4293, 'musk': 2960, 'worldnews': 4923, 'toll': 4511, 'fell': 1665, 'wh': 4849, 'definitely': 1142, 'sack': 3880, 'breitbartnews': 548, 'madness': 2721, 'sport': 4206, 'migrate': 2861, 'criticism': 1029, 'pp': 3444, 'acosta': 41, 'labor': 2562, 'corporation': 981, 'hacker': 1969, 'uc': 4621, 'berkeley': 444, 'gather': 1828, 'wealthy': 4820, 'anticlimate': 237, 'peterdaou': 3329, 'switch': 4350, 'harry': 1997, 'upper': 4696, 'chemical': 733, 'therickydavila': 4451, 'russians': 3871, 'manifesto': 2753, 'trumprussia': 4584, 'moon': 2926, 'centrica': 687, 'changedenying': 704, 'thinktank': 4466, 'path': 3274, 'peril': 3314, 'inte': 2338, 'att': 328, 'globalecoguy': 1869, 'cleanairmomsfl': 782, 'cleanairmoms': 781, 'conversationuk': 958, 'systemic': 4356, 'doubter': 1308, 'famous': 1629, 'cup': 1051, 'necessarily': 3008, 'hahaha': 1971, 'protester': 3553, 'contributes': 950, 'graph': 1912, 'intense': 2344, 'heavy': 2032, 'ashleylgrapes': 302, 'lizwheeler': 2671, 'zika': 4996, 'virus': 4757, 'migration': 2862, 'tens': 4402, 'overfishing': 3218, 'cechruod': 676, 'dispute': 1269, 'eo': 1490, 'nytpolitics': 3122, 'governor': 1904, 'manager': 2748, 'aside': 305, 'museum': 2957, 'kalelkitten': 2494, 'planetgreen': 3374, 'secure': 3992, 'unsure': 4688, 'actual': 51, 'populism': 3427, 'fictional': 1676, 'weatherchannel': 4824, 'flash': 1710, 'task': 4373, 'sometimes': 4170, 'propaganda': 3539, 'maintain': 2731, 'globalcitizen': 1868, 'proven': 3556, 'van': 4724, 'accidentally': 31, 'leecamp': 2613, 'gutting': 1962, 'hardly': 1993, 'healthy': 2020, 'intforestday': 2360, 'transnational': 4556, 'entry': 1482, 'enhance': 1470, 'sends': 4011, 'cat': 653, 'uphold': 4694, 'bw': 601, 'nuke': 3100, 'generate': 1837, 'wasteland': 4807, 'thecaroldanvers': 4427, 'shirt': 4061, 'british': 562, 'overseas': 3221, 'disclosure': 1248, 'pakusalumni': 3241, 'underway': 4651, 'shakeelramay': 4043, 'climatecounts': 799, 'mile': 2871, 'irma': 2380, 'earths': 1369, 'modi': 2915, 'advise': 79, 'transcend': 4552, 'murdoch': 2955, 'wouldnt': 4937, 'agw': 115, 'apparently': 259, 'kinder': 2535, 'morgan': 2929, 'remark': 3717, 'quite': 3594, 'others': 3199, 'recommend': 3665, 'eyeopening': 1604, 'connection': 923, 'heathrow': 2028, 'breach': 540, 'infectious': 2298, 'parliament': 3261, 'ratifies': 3627, 'blind': 492, 'algal': 145, 'convenient': 955, 'repbarbaralee': 3732, 'wikileaks': 4873, 'thepowersthatbe': 4441, 'airline': 125, 'ng': 3043, 'warmth': 4796, 'abstract': 18, 'alexverbeek': 142, 'ridiculous': 3813, 'thaw': 4423, 'corn': 978, 'reduction': 3679, 'forefront': 1742, 'yemen': 4968, 'maralago': 2766, 'syria': 4353, 'resign': 3755, 'option': 3182, 'nigel': 3049, 'iea': 2231, 'usual': 4717, 'precisely': 3455, 'attenborough': 331, 'newscientist': 3035, 'unesco': 4657, 'wo': 4904, 'son': 4171, 'kentut': 2515, 'dari': 1089, 'hewanhewan': 2050, 'purba': 3574, 'adalah': 55, 'penyebab': 3304, 'utama': 4718, 'zaman': 4991, 'dinosaurus': 1227, 'amzne': 200, 'amreading': 197, 'meetc': 2817, 'httpstcogjzhkme': 2134, 'patriot': 3278, 'awaits': 353, 'reel': 3681, 'amongst': 194, 'eciuuk': 1378, 'cordal': 976, 'art': 293, 'rickygervais': 3811, 'creationist': 1016, 'kennedy': 2514, 'hair': 1973, 'flee': 1713, 'distress': 1274, 'jam': 2414, 'eco': 1380, 'alfranken': 143, 'parenthood': 3254, 'shot': 4067, 'ffs': 1674, 'dick': 1211, 'leo': 2625, 'marketwatch': 2776, 'jiyong': 2443, 'explanation': 1579, 'geography': 1843, 'text': 4414, 'sahilkapur': 3888, 'costume': 988, 'actor': 50, 'revisit': 3797, 'equator': 1502, 'vest': 4738, 'amazon': 182, 'june': 2483, 'forecast': 1741, 'skate': 4113, 'commission': 872, 'collect': 857, 'accident': 30, 'jswatz': 2474, 'explains': 1578, 'puanconference': 3564, 'httpstcoospeyqmph': 2149, 'focused': 1726, 'asthma': 321, 'sudden': 4295, 'frequent': 1780, 'spill': 4201, 'singh': 4102, 'average': 349, 'quarter': 3584, 'unconvinced': 4640, 'planning': 3375, 'reutersscience': 3789, 'skepticscience': 4117, 'httpstcoihdspigy': 2138, 'pass': 3270, 'savmontano': 3919, 'minnesota': 2885, 'wwf': 4947, 'seeker': 3997, 'scarcity': 3929, 'esm': 1515, 'cfigueres': 695, 'publication': 3566, 'voyage': 4776, 'neglect': 3013, 'credible': 1019, 'alarmism': 132, 'disagree': 1240, 'democrats': 1168, 'repeatedly': 3735, 'nytimesworld': 3118, 'evidently': 1543, 'essay': 1519, 'anncoulter': 220, 'stagnant': 4218, 'heater': 2026, 'recycle': 3671, 'transition': 4555, 'stevenmufson': 4250, 'tony': 4520, 'seanmcelwee': 3978, 'gasket': 1826, 'scaramucci': 3928, 'cripple': 1024, 'sustainable': 4337, 'swedish': 4344, 'middleclass': 2855, 'breath': 544, 'erase': 1507, 'prior': 3494, 'yearold': 4965, 'arnoldschwarzenegger': 289, 'biz': 481, 'scenario': 3933, 'mil': 2869, 'bentler': 443, 'worldwide': 4926, 'davidsuzukifdn': 1102, 'strip': 4273, 'irena': 2378, 'horrific': 2105, 'niggas': 3052, 'machine': 2718, 'negate': 3011, 'billmaher': 466, 'unfortunate': 4661, 'teen': 4391, 'property': 3544, 'firsthand': 1701, 'myclimateaction': 2963, 'nail': 2970, 'fifth': 1679, 'tfw': 4415, 'hopefully': 2101, 'redhotsquirrel': 3674, 'northern': 3077, 'hemisphere': 2040, 'icecap': 2218, 'writer': 4943, 'tragic': 4547, 'tale': 4364, 'swannyqld': 4339, 'delegation': 1153, 'stack': 4214, 'title': 4502, 'georgetakei': 1847, 'cure': 1053, 'jaredwyand': 2424, 'maggienyt': 2724, 'embarrass': 1434, 'loom': 2692, 'plutocracy': 3388, 'teens': 4392, 'humandriven': 2190, 'steal': 4239, 'newsweek': 3038, 'pussy': 3578, 'prepping': 3466, 'prep': 3463, 'stress': 4271, 'au': 337, 'institution': 2330, 'plea': 3381, 'grass': 1914, 'stream': 4269, 'alternativefacts': 170, 'few': 1672, 'retrojace': 3781, 'tryna': 4591, 'sumn': 4309, 'legit': 2621, 'insist': 2321, 'province': 3558, 'zealot': 4993, 'jayzimmer': 2425, 'httpstcozyozkkfr': 2178, 'reassure': 3652, 'oreillyfactor': 3188, 'being': 429, 'ttrogdon': 4593, 'diet': 1216, 'hook': 2098, 'pruitts': 3561, 'entirely': 1481, 'philippine': 3339, 'duterte': 1354, 'nato': 2993, 'gdp': 1832, 'parisaccord': 3257, 'negligible': 3014, 'mit': 2900, 'extraordinary': 1594, 'criticize': 1030, 'mehdirhasan': 2820, 'exacerbate': 1548, 'hazard': 2013, 'alliance': 159, 'witch': 4895, 'ol': 3156, 'kim': 2531, 'mobilize': 2909, 'rid': 3812, 'rwanda': 3874, 'robbiegramer': 3828, 'bleak': 490, 'dnc': 1280, 'donna': 1301, 'technological': 4386, 'present': 3468, 'antiglobal': 238, 'sierra': 4082, 'everyday': 1537, 'judith': 2477, 'spark': 4185, 'angle': 215, 'sheet': 4051, 'fly': 1724, 'immigrant': 2250, 'reinadeafrica': 3701, 'confronts': 914, 'altnoaa': 173, 'murray': 2956, 'lgbtq': 2639, 'names': 2972, 'turnbulls': 4604, 'unbelievable': 4636, 'skewer': 4118, 'coverage': 1004, 'complicate': 890, 'affordable': 93, 'capital': 631, 'curriculum': 1057, 'bv': 600, 'ryan': 3876, 'gentleman': 1839, 'urban': 4701, 'newsciencewrld': 3034, 'strange': 4267, 'shame': 4045, 'expose': 1583, 'manipulated': 2755, 'sham': 4044, 'sam': 3895, 'birther': 476, 'graze': 1918, 'rangeland': 3616, 'compare': 884, 'elite': 1420, 'equity': 1503, 'material': 2793, 'memory': 2828, 'quiet': 3591, 'hollywood': 2084, 'praise': 3449, 'scrap': 3964, 'virtually': 4756, 'tomleewalker': 4514, 'asshole': 316, 'dim': 1223, 'dominant': 1297, 'ideology': 2225, 'unspokesperson': 4686, 'kimoon': 2532, 'resourceful': 3765, 'immune': 2252, 'clock': 819, 'tick': 4487, 'jamisonfoser': 2419, 'woolly': 4915, 'mammoth': 2744, 'relationship': 3707, 'braddjaffy': 530, 'httpstcoylosrinbs': 2174, 'efficiency': 1402, 'rfk': 3803, 'uncovers': 4641, 'cleanup': 786, 'employment': 1447, 'super': 4314, 'theorist': 4439, 'bald': 375, 'eagle': 1359, 'bed': 417, 'excuse': 1560, 'regulator': 3699, 'guest': 1956, 'foodtank': 1731, 'building': 582, 'httpstconyltyn': 2146, 'senkamalaharris': 4014, 'gameofthrones': 1821, 'recall': 3655, 'rio': 3820, 'batter': 397, 'cnnmoney': 834, 'responsibility': 3769, 'experiment': 1575, 'speaking': 4188, 'speakerryan': 4187, 'lake': 2568, 'ski': 4119, 'resort': 3763, 'scottpruitt': 3960, 'cbcalerts': 666, 'relocate': 3714, 'httpstcomyuum': 2144, 'unqualified': 4681, 'incompetent': 2275, 'poop': 3420, 'hurricaneirma': 2203, 'propublica': 3547, 'zeroco': 4995, 'itstimetochange': 2401, 'weigh': 4836, 'defunds': 1145, 'vault': 4730, 'sciencemagazine': 3943, 'harm': 1994, 'pittsburgh': 3362, 'petroleum': 3333, 'institute': 2329, 'yceek': 4961, 'obvious': 3134, 'charity': 715, 'feminist': 1669, 'heed': 2035, 'warning': 4798, 'envoy': 1489, 'becomes': 416, 'fahrenthold': 1614, 'ngolo': 3044, 'kantes': 2498, 'statesman': 4235, 'tooth': 4522, 'fairy': 1619, 'breakingnews': 543, 'anywhere': 250, 'fair': 1618, 'passionate': 3271, 'coachella': 838, 'music': 2958, 'festival': 1670, 'trailer': 4549, 'principle': 3493, 'knoctua': 2544, 'apology': 257, 'edition': 1393, 'dumber': 1345, 'obliterate': 3131, 'domestic': 1296, 'abuse': 21, 'swiss': 4349, 'grand': 1909, 'canyon': 628, 'sweden': 4343, 'largely': 2578, 'retard': 3776, 'nwf': 3106, 'parasite': 3252, 'julia': 2480, 'louisdreyfus': 2703, 'mega': 2819, 'remedy': 3719, 'zoe': 4998, 'fortunemagazine': 1751, 'francis': 1765, 'presldentbannon': 3477, 'houstonchron': 2119, 'reveldor': 3792, 'govern': 1901, 'degrees': 1150, 'magazine': 2723, 'drastic': 1319, 'reuterspolitics': 3788, 'tedtalks': 4390, 'drown': 1334, 'kellyanne': 2510, 'conway': 963, 'dodge': 1289, 'jwalkenrdc': 2491, 'supreme': 4324, 'honey': 2095, 'bee': 418, 'beer': 420, 'relief': 3710, 'relation': 3706, 'salvesayson': 3894, 'samanthadpage': 3896, 'stefanmolyneux': 4240, 'advocacy': 83, 'horn': 2103, 'vs': 4778, 'bbh': 406, 'subject': 4287, 'advance': 76, 'snowball': 4151, 'terrestrial': 4405, 'biosphere': 473, 'counteract': 996, 'underestimate': 4643, 'rclimate': 3631, 'greener': 1924, 'benshapiro': 442, 'click': 791, 'taiwan': 4362, 'apologize': 256, 'allegation': 153, 'womensmarch': 4910, 'whyimarch': 4868, 'wife': 4872, 'corner': 979, 'drjillstein': 1329, 'senwhitehouse': 4019, 'unravel': 4682, 'figure': 1682, 'concentration': 897, 'hurricaneharvey': 2202, 'shade': 4041, 'insightful': 2320, 'provide': 3557, 'detailed': 1199, 'breakdown': 542, 'category': 657, 'sheilagunnreid': 4052, 'luisbaram': 2712, 'keystone': 2523, 'teamtrump': 4383, 'payment': 3290, 'sa': 3879, 'globalgoalsun': 1871, 'robinson': 3833, 'btw': 575, 'pappiness': 3251, 'agschneiderman': 113, 'curtail': 1059, 'hobble': 2080, 'somehow': 4167, 'clever': 790, 'healthdamaging': 2019, 'conversion': 960, 'therapy': 4442, 'bike': 462, 'ka': 2492, 'disband': 1246, 'demonstrate': 1169, 'katyturnbc': 2506, 'adult': 75, 'field': 1678, 'spar': 4184, 'sand': 3900, 'unveils': 4691, 'severity': 4035, 'christophernfox': 759, 'witness': 4901, 'coincidence': 850, 'lamarsmithtx': 2571, 'politically': 3405, 'conclusion': 903, 'politixgal': 3413, 'toe': 4506, 'tobacco': 4503, 'org': 3189, 'ryanlcooper': 3877, 'stephens': 4245, 'rhetoric': 3804, 'williamlegate': 4880, 'cnbci': 830, 'ghoshamitav': 1853, 'et': 1523, 'traditional': 4545, 'dislike': 1261, 'soros': 4175, 'leftist': 2615, 'liar': 2641, 'combine': 868, 'dmreporter': 1278, 'palace': 3243, 'httpstcoeujncyn': 2131, 'humaninduced': 2191, 'broadcast': 565, 'mcnees': 2807, 'savelibertst': 3915, 'moore': 2927, 'coauthor': 845, 'thankfully': 4418, 'misogynistic': 2895, 'crush': 1038, 'immensely': 2249, 'opposite': 3178, 'httpstcocoppufd': 2127, 'couple': 1000, 'josh': 2463, 'frydenberg': 1793, 'floor': 1720, 'flaw': 1712, 'ew': 1546, 'wale': 4785, 'tourism': 4534, 'predictable': 3457, 'unacceptable': 4635, 'kaput': 2500, 'httpstcorbzvrtcm': 2153, 'rogerhelmermep': 3840, 'specifically': 4193, 'error': 1512, 'owner': 3226, 'shadow': 4042, 'forum': 1752, 'venice': 4733, 'award': 354, 'delusion': 1160, 'seasonal': 3983, 'season': 3982, 'fully': 1803, 'mancaused': 2749, 'acampbell': 24, 'grandchild': 1910, 'plane': 3370, 'yea': 4962, 'views': 4750, 'circle': 763, 'robflaherty': 3831, 'selfish': 4002, 'prefer': 3459, 'shill': 4058, 'pal': 3242, 'jamienzherald': 2417, 'continuous': 945, 'sensible': 4017, 'greg': 1934, 'moral': 2928, 'panic': 3249, 'confused': 916, 'stats': 4236, 'variety': 4727, 'delhi': 1156, 'useless': 4714, 'yrs': 4986, 'notion': 3083, 'redistribution': 3675, 'ecosystems': 1390, 'wellbeing': 4841, 'palau': 3244, 'thrive': 4479, 'flipper': 1716, 'root': 3851, 'cub': 1044, 'hed': 2034, 'willful': 4879, 'silence': 4089, 'cattle': 659, 'hidden': 2054, 'subsidy': 4289, 'alternative': 169, 'grateful': 1915, 'gizmodo': 1860, 'sugar': 4298, 'obesity': 3130, 'hint': 2067, 'brithume': 561, 'lunatic': 2714, 'musical': 2959, 'southeast': 4181, 'hardest': 1992, 'england': 1468, 'unusual': 4689, 'koala': 2548, 'drink': 1324, 'cheer': 727, 'urgently': 4706, 'yahoo': 4954, 'bullet': 583, 'nude': 3099, 'poise': 3396, 'assembly': 312, 'gulf': 1958, 'dumbass': 1344, 'habit': 1966, 'professional': 3518, 'everywhere': 1541, 'rainfall': 3609, 'theatlantic': 4425, 'condemn': 904, 'rock': 3836, 'tar': 4371, 'torture': 4527, 'gag': 1815, 'netherlands': 3025, 'hypothetical': 2212, 'democracy': 1164, 'qampa': 3581, 'sdgs': 3972, 'oecd': 3144, 'congrats': 918, 'brazile': 539, 'thatcher': 4421, 'understood': 4649, 'pauledawson': 3282, 'slave': 4129, 'sec': 3986, 'hypocritical': 2210, 'hottest': 2113, 'um': 4631, 'drudgereport': 1335, 'enormous': 1473, 'arstechnica': 292, 'nydailynews': 3110, 'ax': 360, 'roast': 3827, 'thedailyedge': 4431, 'antisemitic': 241, 'carlzimmer': 643, 'wisconsin': 4892, 'pa': 3231, 'highestranking': 2058, 'highcountrynews': 2057, 'collaboration': 854, 'induced': 2291, 'scientifically': 3949, 'violent': 4754, 'earthquake': 1368, 'huffpostgreen': 2183, 'holiday': 2083, 'trash': 4560, 'bigjoebastardi': 457, 'meme': 2826, 'troll': 4575, 'harder': 1991, 'embrace': 1436, 'po': 3391, 'gayriot': 1831, 'ai': 118, 'bros': 567, 'justify': 2488, 'lefty': 2616, 'goddersbloom': 1888, 'juicediem': 2478, 'burning': 589, 'enviro': 1484, 'prison': 3497, 'rememberwhentrump': 3721, 'accomplish': 32, 'rworldnews': 3875, 'bradplumer': 531, 'mulvaney': 2952, 'doctrine': 1286, 'hv': 2206, 'fuckery': 1798, 'httpstcojhdmbynpnp': 2139, 'khanoisseur': 2524, 'nowhere': 3090, 'nexusmedianews': 3042, 'affordability': 92, 'millennial': 2875, 'antitrump': 242, 'nytopinion': 3121, 'regime': 3691, 'idaho': 2222, 'naturebrains': 2997, 'alien': 149, 'restriction': 3773, 'abcworldnews': 7, 'express': 1585, 'incompatible': 2274, 'doug': 1310, 'az': 361, 'polarbears': 3400, 'finland': 1697, 'caused': 662, 'told': 4509, 'sadly': 3883, 'applaud': 262, 'omanreagan': 3160, 'member': 2825, 'condom': 906, 'seasaver': 3981, 'httpstcomyotghlgk': 2143, 'revolution': 3800, 'sooner': 4174, 'phenomenon': 3338, 'rapidly': 3623, 'trick': 4570, 'recently': 3658, 'piyushgoyal': 3364, 'solarrich': 4162, 'certain': 692, 'engineer': 1466, 'artificial': 296, 'expand': 1568, 'uneducated': 4655, 'forbes': 1739, 'camp': 616, 'adm': 66, 'unled': 4672, 'ruse': 3867, 'gallup': 1819, 'liability': 2640, 'cake': 607, 'aerosol': 85, 'canadas': 621, 'hudson': 2180, 'discrimination': 1251, 'brhodes': 552, 'grave': 1916, 'owenjones': 3224, 'ukip': 4627, 'ceos': 690, 'exxons': 1602, 'tweeted': 4609, 'changeits': 706, 'wonderful': 4912, 'appoints': 267, 'myron': 2964, 'charlatan': 716, 'undp': 4654, 'corruption': 985, 'couldve': 992, 'universal': 4668, 'somebody': 4166, 'forgot': 1748, 'altusda': 175, 'cape': 630, 'excite': 1558, 'covfefe': 1006, 'ancient': 205, 'concentrate': 896, 'nomination': 3066, 'believer': 433, 'titanic': 4501, 'ozone': 3230, 'jolyonmaugham': 2457, 'wikipedia': 4874, 'partner': 3266, 'tire': 4500, 'smog': 4144, 'dailycaller': 1072, 'holy': 2086, 'barron': 391, 'bare': 387, 'whale': 4851, 'cllrbsilvester': 818, 'amike': 192, 'werent': 4842, 'ethic': 1525, 'engagement': 1465, 'winner': 4887, 'rn': 3825, 'import': 2259, 'jilevin': 2437, 'sincerely': 4099, 'sudan': 4294, 'confirms': 911, 'threatened': 4476, 'tour': 4533, 'legitimate': 2622, 'mostly': 2934, 'climateguardia': 805, 'meteorological': 2839, 'leaked': 2607, 'dire': 1232, 'prioritize': 3495, 'villain': 4752, 'karl': 2503, 'precipitation': 3454, 'replace': 3736, 'stir': 4257, 'bravo': 538, 'climatedesk': 801, 'islamaphobia': 2389, 'konk': 2551, 'proclaim': 3510, 'misogynist': 2894, 'homophobe': 2089, 'obsess': 3133, 'impend': 2255, 'kit': 2538, 'maryland': 2785, 'brian': 553, 'band': 379, 'philstockworld': 3341, 'signature': 4086, 'confuse': 915, 'index': 2282, 'kaine': 2493, 'committed': 875, 'newly': 3031, 'disruption': 1271, 'chase': 723, 'retirement': 3779, 'cyclone': 1066, 'directive': 1235, 'mandate': 2750, 'brand': 536, 'tshirt': 4592, 'utter': 4719, 'therhs': 4450, 'practical': 3447, 'enrich': 1476, 'httpstcoxduazntsva': 2169, 'piyushgoyaloffc': 3365, 'german': 1848, 'describe': 1188, 'notable': 3079, 'weight': 4837, 'undone': 4653, 'intervene': 2356, 'ab': 1, 'bite': 479, 'landmark': 2573, 'expedition': 1571, 'solid': 4163, 'pack': 3236, 'outrageous': 3211, 'tabloid': 4358, 'lifeblood': 2650, 'transformed': 4554, 'unseasonably': 4684, 'badlandsnps': 370, 'consult': 937, 'peddoc': 3296, 'ken': 2512, 'highly': 2060, 'nicaragua': 3046, 'gravity': 1917, 'search': 3980, 'joshhaner': 2467, 'defiance': 1139, 'strongertogether': 4275, 'border': 516, 'kate': 2504, 'appointment': 266, 'klein': 2540, 'philosophy': 3340, 'collective': 858, 'oops': 3167, 'flint': 1715, 'nonexistent': 3071, 'httpstcoqxepk': 2152, 'profterryhughes': 3524, 'httpstcouvirfobw': 2163, 'asian': 304, 'darn': 1091, 'franken': 1768, 'elonmusk': 1427, 'propel': 3542, 'campus': 619, 'truths': 4589, 'csmonitor': 1042, 'sids': 4081, 'omans': 3161, 'mouth': 2940, 'muslim': 2961, 'climategroup': 804, 'so': 4154, 'brutal': 572, 'theagu': 4424, 'effectively': 1401, 'sciencebased': 3941, 'nerve': 3022, 'dystopian': 1358, 'edyong': 1398, 'hungry': 2199, 'imwithher': 2266, 'newspaper': 3037, 'derange': 1186, 'sexism': 4037, 'ryanmaue': 3878, 'lbc': 2598, 'chaos': 712, 'ironic': 2381, 'lisa': 2662, 'friday': 1783, 'filmmaker': 1687, 'thursday': 4484, 'thunderstorm': 4483, 'hybrid': 2207, 'disappearance': 1242, 'andrew': 207, 'undermine': 4644, 'fundamental': 1806, 'indianexpress': 2285, 'petergleick': 3330, 'academy': 23, 'expense': 1572, 'ability': 8, 'training': 4551, 'httpstcotdclgwez': 2157, 'curryja': 1058, 'emotional': 1443, 'bogus': 507, 'whos': 4865, 'pb': 3291, 'supercomputer': 4315, 'reagan': 3641, 'contrast': 948, 'awful': 359, 'epic': 1495, 'proliferation': 3533, 'revkin': 3799, 'blue': 501, 'gmb': 1883, 'historical': 2073, 'intensify': 2345, 'se': 3973, 'changeglobal': 705, 'jaketapper': 2413, 'within': 4899, 'classic': 779, 'drcraigemerson': 1321, 'bigoted': 459, 'dutch': 1353, 'transport': 4557, 'shortage': 4066, 'opposes': 3177, 'lowkey': 2709, 'suicide': 4302, 'authority': 345, 'economically': 1384, 'partnership': 3267, 'chorus': 747, 'sort': 4177, 'credit': 1020, 'stick': 4254, 'che': 725, 'disable': 1239, 'aaas': 0, 'asamjulian': 299, 'scorch': 3955, 'cloudy': 824, 'maldives': 2740, 'collaborate': 853, 'buddy': 577, 'lenoretaylor': 2624, 'oslo': 3197, 'weatherkait': 4825, 'medical': 2813, 'terror': 4408, 'pave': 3287, 'lakes': 2569, 'eruption': 1513, 'thin': 4459, 'pointless': 3395, 'cherry': 735, 'op': 3168, 'facebook': 1608, 'barber': 386, 'tucker': 4594, 'yalee': 4957, 'diversity': 1276, 'gsummit': 1945, 'criminology': 1023, 'hatred': 2008, 'upon': 4695, 'found': 1755, 'mikelevinca': 2866, 'empirical': 1444, 'cyclical': 1065, 'nbcnews': 3003, 'doubtful': 1309, 'housescience': 2116, 'joe': 2445, 'silver': 4092, 'intervention': 2357, 'declaration': 1127, 'cuz': 1062, 'intlspectator': 2361, 'physical': 3350, 'nytclimate': 3115, 'outlet': 3207, 'wheat': 4855, 'heatwave': 2029, 'st': 4213, 'king': 2537, 'stole': 4259, 'shed': 4050, 'sweat': 4341, 'saudi': 3912, 'charlesmilander': 718, 'antilgbt': 239, 'televise': 4396, 'kelp': 2511, 'reporting': 3740, 'kenyan': 2517, 'esquire': 1518, 'whoever': 4863, 'httpstcockamqurlwc': 2126, 'cheese': 728, 'louisiana': 2704, 'yung': 4987, 'contempt': 940, 'annoy': 224, 'suppress': 4321, 'whove': 4867, 'civilisation': 771, 'enact': 1452, 'grant': 1911, 'tide': 4488, 'nancysinatra': 2973, 'natureclimate': 2998, 'mangrove': 2751, 'dinograndoni': 1225, 'orgs': 3193, 'httpstcotfswyjwczq': 2158, 'calculate': 609, 'lamar': 2570, 'smith': 4143, 'accepts': 28, 'mate': 2792, 'sarah': 3904, 'palin': 3245, 'pas': 3269, 'kengarex': 2513, 'issac': 2396, 'thanksgiving': 4420, 'correlation': 983, 'ananavarro': 203, 'finger': 1695, 'journalism': 2469, 'abcpolitics': 6, 'buffoon': 579, 'jesus': 2434, 'dry': 1338, 'raining': 3610, 'pocket': 3392, 'garden': 1824, 'tolerate': 4510, 'westwingreport': 4845, 'ipcc': 2375, 'distract': 1273, 'resurrect': 3775, 'daveweigel': 1096, 'strongly': 4277, 'insufficient': 2333, 'askin': 307, 'elephant': 1418, 'awesome': 358, 'telegraphnews': 4395, 'saving': 3918, 'nextgenclimate': 3041, 'content': 941, 'naomioreskes': 2976, 'nypost': 3113, 'increasingly': 2279, 'exercise': 1562, 'gove': 1900, 'english': 1469, 'questionable': 3588, 'imaginary': 2245, 'paint': 3239, 'crock': 1032, 'size': 4112, 'margin': 2769, 'wmbtweets': 4902, 'fallout': 1624, 'wouldve': 4938, 'ableg': 10, 'progressoutlook': 3529, 'goodness': 1895, 'dissent': 1272, 'spotlight': 4208, 'jeffreyguterman': 2429, 'walker': 4787, 'alert': 140, 'marker': 2774, 'podcast': 3393, 'creature': 1018, 'provoke': 3559, 'inuit': 2362, 'boycott': 527, 'product': 3512, 'eclipse': 1379, 'atlanta': 325, 'cuomo': 1050, 'insider': 2318, 'max': 2800, 'calamity': 608, 'date': 1094, 'worst': 4933, 'rig': 3815, 'rogueepastaff': 3842, 'hired': 2070, 'jane': 2421, 'rollingstone': 3848, 'immediately': 2248, 'foundation': 1756, 'skin': 4121, 'lab': 2560, 'postgreen': 3437, 'disconnect': 1249, 'determine': 1200, 'mode': 2911, 'exceptional': 1556, 'communist': 880, 'sydney': 4351, 'fucker': 1797, 'edit': 1392, 'ecosensenow': 1388, 'ton': 4517, 'childrens': 739, 'kanye': 2499, 'maker': 2737, 'cheeto': 729, 'nov': 3086, 'reclaimanglesea': 3662, 'gmbutts': 1884, 'httpstcowvubdxuqu': 2166, 'worldresources': 4924, 'governance': 1902, 'disinformation': 1260, 'jesse': 2433, 'watters': 4812, 'native': 2992, 'naturenews': 2999, 'unproven': 4680, 'separate': 4020, 'httptcowgxvifdvz': 2179, 'pine': 3358, 'useful': 4713, 'descend': 1187, 'reutersipsos': 3787, 'badass': 367, 'httpstcowuuhkm': 2165, 'chancellor': 702, 'quietly': 3592, 'confident': 908, 'extremes': 1597, 'uberfacts': 4620, 'dan': 1081, 'angel': 211, 'tactic': 4360, 'kong': 2550, 'ang': 210, 'meteorologist': 2840, 'joebiden': 2446, 'jury': 2486, 'onto': 3166, 'theintercept': 4437, 'larry': 2580, 'surge': 4327, 'carlson': 642, 'abrupt': 14, 'snowstorm': 4153, 'ne': 3005, 'wise': 4893, 'clearer': 788, 'eight': 1408, 'islam': 2388, 'slightly': 4133, 'kansa': 2496, 'admission': 70, 'rep': 3730, 'herd': 2043, 'equation': 1501, 'thesnp': 4452, 'western': 4844, 'frankmcveety': 1770, 'church': 761, 'pleistocene': 3384, 'eloquent': 1428, 'aquatic': 274, 'consumption': 938, 'photographic': 3347, 'lil': 2657, 'herpes': 2048, 'georgemonbiot': 1846, 'homophobes': 2090, 'deadline': 1111, 'patrick': 3277, 'sing': 4101, 'yell': 4967, 'inferno': 2299, 'angela': 212, 'goin': 1889, 'lifestyle': 2651, 'fails': 1616, 'port': 3428, 'transportation': 4558, 'rtcom': 3858, 'australias': 343, 'drone': 1330, 'planetarysec': 3373, 'ethnic': 1526, 'glow': 1881, 'sinister': 4105, 'britain': 560, 'notjoshearnest': 3084, 'looney': 2693, 'nowadays': 3089, 'career': 640, 'bobinglis': 505, 'chemtrails': 734, 'mann': 2760, 'pitbull': 3361, 'faux': 1648, 'outrage': 3210, 'rush': 3868, 'glenont': 1865, 'cenkuygur': 680, 'actualepafacts': 52, 'removal': 3725, 'csiro': 1041, 'storage': 4262, 'hypothesis': 2211, 'devastation': 1202, 'drug': 1336, 'oust': 3203, 'agroforestry': 111, 'conception': 899, 'octorg': 3141, 'youthvgov': 4982, 'prop': 3538, 'antichoice': 236, 'aware': 355, 'annehidalgo': 221, 'polluting': 3417, 'infowars': 2305, 'revive': 3798, 'dodotribe': 1290, 'server': 4025, 'peerreviewed': 3297, 'instance': 2326, 'testimony': 4412, 'phony': 3344, 'dapl': 1087, 'frankthedoorman': 1771, 'peoplebernie': 3306, 'ga': 1814, 'float': 1717, 'jinping': 2442, 'dream': 1322, 'aitruthfilm': 126, 'gw': 1964, 'intellectual': 2341, 'doin': 1294, 'baffle': 371, 'arabia': 276, 'michaelhallida': 2850, 'integrate': 2339, 'outdated': 3205, 'closer': 822, 'dishonest': 1259, 'jacquelyngill': 2412, 'survival': 4332, 'costly': 987, 'tasmania': 4374, 'regressive': 3694, 'robintransition': 3834, 'jacket': 2408, 'slavery': 4130, 'wilderness': 4876, 'nl': 3060, 'mikemchargue': 2868, 'johncolemanmrwx': 2448, 'hiv': 2077, 'paulkrugman': 3285, 'stem': 4242, 'springst': 4212, 'kerstin': 2519, 'langenberger': 2575, 'katrina': 2505, 'emmanuel': 1441, 'vitally': 4763, 'yang': 4959, 'blackout': 484, 'origin': 3194, 'httpstcoeogkj': 2130, 'truthout': 4588, 'emorwee': 1442, 'similar': 4093, 'instruct': 2331, 'recipient': 3660, 'resiliency': 3758, 'crony': 1033, 'horizon': 2102, 'jeffbezos': 2428, 'kurtschlichter': 2555, 'scammer': 3925, 'senbookeroffice': 4009, 'agscottpruitt': 114, 'default': 1132, 'sarcasm': 3907, 'redtraccoon': 3677, 'amyklobuchar': 199, 'trading': 4544, 'httpstcotwfnlfxnw': 2160, 'defunding': 1144, 'lunch': 2715, 'sciencemarchdc': 3944, 'brought': 569, 'ags': 112, 'ass': 309, 'label': 2561, 'lagos': 2567, 'wicked': 4870, 'opposition': 3179, 'warmists': 4795, 'frozen': 1791, 'laughable': 2589, 'africarenewal': 98, 'exact': 1549, 'shred': 4074, 'austin': 340, 'kantefacts': 2497, 'convinced': 962, 'andrewgillum': 208, 'slogan': 4134, 'lt': 2710, 'hail': 1972, 'compost': 891, 'loser': 2697, 'glimpse': 1866, 'universe': 4669, 'ronald': 3849, 'censorship': 682, 'weekly': 4834, 'paulbegala': 3281, 'marrakesh': 2780, 'devote': 1206, 'wood': 4914, 'robot': 3835, 'prominent': 3534, 'slap': 4126, 'abolish': 11, 'duty': 1355, 'fav': 1649, 'prayer': 3451, 'degradation': 1147, 'netherworld': 3026, 'tourist': 4535, 'scistarter': 3954, 'diseases': 1256, 'dat': 1092, 'peoplesclimate': 3307, 'globalists': 1874, 'tough': 4532, 'nightmare': 3054, 'fever': 1671, 'outta': 3214, 'cough': 989, 'nigeria': 3050, 'politicalmiller': 3406, 'waterkeeper': 4810, 'kileykroh': 2528, 'virginia': 4755, 'humankind': 2194, 'httpstcormwcydnue': 2154, 'httpstcozdrlwqz': 2175, 'inquiry': 2313, 'justin': 2489, 'fuckin': 1799, 'till': 4490, 'menace': 2830, 'confusion': 917, 'quits': 3595, 'yg': 4973, 'httpstcoslquvvwr': 2155, 'cease': 675, 'keepparis': 2508, 'elitist': 1421, 'legislator': 2620, 'lee': 2612, 'casino': 651, 'thinking': 4463, 'lcvoters': 2599, 'cheetos': 730, 'chrismeloni': 755, 'slew': 4132, 'mosquito': 2933, 'msm': 2947, 'altuscis': 174, 'panas': 3247, 'petty': 3334, 'tht': 4482, 'architect': 278, 'greennewdeal': 1930, 'johnny': 2452, 'ugh': 4623, 'sapi': 3903, 'termasuk': 4404, 'unreal': 4683, 'milk': 2874, 'whack': 4850, 'rodent': 3839, 'protein': 3551, 'remarkably': 3718, 'imtheantitrump': 2264, 'harvest': 2002, 'larsen': 2581, 'hammer': 1980, 'dumptrump': 1348, 'sweater': 4342, 'jiminhofe': 2441, 'clarifies': 775, 'foolish': 1733, 'ie': 2230, 'delusional': 1161, 'split': 4205, 'premature': 3460, 'contain': 939, 'threatens': 4477, 'diego': 1215, 'dion': 1228, 'thedailyshow': 4432, 'crash': 1010, 'alaskas': 137, 'istanbul': 2398, 'premise': 3462, 'hemantmehta': 2039, 'climatechangetp': 797, 'fao': 1633, 'primarily': 3489, 'gunshot': 1960}\n",
      "  (0, 4583)\t0.20466253924334757\n",
      "  (0, 4397)\t0.349532292119421\n",
      "  (0, 3950)\t0.302244127987298\n",
      "  (0, 3940)\t0.31675541850084493\n",
      "  (0, 3403)\t0.3700966811881651\n",
      "  (0, 3288)\t0.4341706027008079\n",
      "  (0, 792)\t0.16978936000315\n",
      "  (0, 703)\t0.08753301180756276\n",
      "  (0, 333)\t0.5313085667870435\n",
      "  (1, 3857)\t0.061312549206070766\n",
      "  (1, 2926)\t0.31630663174974155\n",
      "  (1, 2809)\t0.23819456684456342\n",
      "  (1, 1716)\t0.3801095514366252\n",
      "  (1, 1700)\t0.22446242512939274\n",
      "  (1, 1293)\t0.3425892703930745\n",
      "  (1, 792)\t0.05054078169142965\n",
      "  (1, 703)\t0.05211147318627372\n",
      "  (1, 612)\t0.20144935011825965\n",
      "  (1, 286)\t0.6938071474518289\n",
      "  (2, 4790)\t0.3954417492788996\n",
      "  (2, 4583)\t0.24340147206888194\n",
      "  (2, 3649)\t0.43851325244314154\n",
      "  (2, 2527)\t0.4874903008795346\n",
      "  (2, 1607)\t0.47712194334883745\n",
      "  (2, 1292)\t0.32521493086569164\n",
      "  :\t:\n",
      "  (11070, 792)\t0.08162727698891953\n",
      "  (11070, 703)\t0.08416406540854775\n",
      "  (11070, 130)\t0.38680234939446656\n",
      "  (11071, 4792)\t0.16514776203146989\n",
      "  (11071, 4788)\t0.32817079277601735\n",
      "  (11071, 4583)\t0.13938941127155977\n",
      "  (11071, 3857)\t0.0701421897602955\n",
      "  (11071, 2377)\t0.4023788123346967\n",
      "  (11071, 1891)\t0.3833848215455305\n",
      "  (11071, 1867)\t0.11499664988295463\n",
      "  (11071, 1680)\t0.19889348518144337\n",
      "  (11071, 1298)\t0.2212772346158882\n",
      "  (11071, 1083)\t0.31292639824529295\n",
      "  (11071, 1001)\t0.31943018390286937\n",
      "  (11071, 764)\t0.3670684135231402\n",
      "  (11071, 581)\t0.3087781191953381\n",
      "  (11072, 4921)\t0.29068682754122005\n",
      "  (11072, 4583)\t0.209825669852897\n",
      "  (11072, 3472)\t0.3406869964762633\n",
      "  (11072, 3185)\t0.3849886690708066\n",
      "  (11072, 2809)\t0.4101952549500014\n",
      "  (11072, 2044)\t0.4527545128370701\n",
      "  (11072, 1561)\t0.46724173025298316\n",
      "  (11072, 792)\t0.08703636319638215\n",
      "  (11072, 703)\t0.08974125360051888\n",
      "Naive Bayes Accuracy Score ->  66.77201854193004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.93      0.10      0.18       380\n",
      "           0       0.73      0.11      0.20       725\n",
      "           1       0.64      0.94      0.76      2582\n",
      "           2       0.76      0.58      0.66      1059\n",
      "\n",
      "    accuracy                           0.67      4746\n",
      "   macro avg       0.77      0.43      0.45      4746\n",
      "weighted avg       0.71      0.67      0.61      4746\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score ->  71.59713442899283\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.75      0.36      0.49       380\n",
      "           0       0.62      0.36      0.46       725\n",
      "           1       0.73      0.87      0.79      2582\n",
      "           2       0.71      0.71      0.71      1059\n",
      "\n",
      "    accuracy                           0.72      4746\n",
      "   macro avg       0.70      0.58      0.61      4746\n",
      "weighted avg       0.71      0.72      0.70      4746\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 366>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    364\u001b[0m vectoriser \u001b[38;5;241m=\u001b[39m TfidfVectorizer(ngram_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m), max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500000\u001b[39m)\n\u001b[1;32m    365\u001b[0m \u001b[38;5;66;03m#vectoriser = TfidfVectorizer(ngram_range=(1,2), max_features=5000)\u001b[39;00m\n\u001b[0;32m--> 366\u001b[0m \u001b[43mvectoriser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo. of feature_words: \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(vectoriser\u001b[38;5;241m.\u001b[39mget_feature_names()))\n\u001b[1;32m    371\u001b[0m \u001b[38;5;66;03m#obj = TfidfVectorizer()\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;66;03m#corpus = ['This is sample document.', 'another random document.', 'third sample document text']\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;66;03m#obj.fit_transform(X_train)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:2049\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   2042\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_for_unused_params()\n\u001b[1;32m   2043\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf \u001b[38;5;241m=\u001b[39m TfidfTransformer(\n\u001b[1;32m   2044\u001b[0m     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[1;32m   2045\u001b[0m     use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_idf,\n\u001b[1;32m   2046\u001b[0m     smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_idf,\n\u001b[1;32m   2047\u001b[0m     sublinear_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublinear_tf,\n\u001b[1;32m   2048\u001b[0m )\n\u001b[0;32m-> 2049\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2050\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:1338\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1330\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1331\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1332\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1333\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1334\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1335\u001b[0m             )\n\u001b[1;32m   1336\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1338\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[1;32m   1341\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:1209\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1207\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[1;32m   1208\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m-> 1209\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1210\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1211\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:111\u001b[0m, in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m preprocessor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m         doc \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    113\u001b[0m         doc \u001b[38;5;241m=\u001b[39m tokenizer(doc)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:69\u001b[0m, in \u001b[0;36m_preprocess\u001b[0;34m(doc, accent_function, lower)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m\"\"\"Chain together an optional series of text preprocessing steps to\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03mapply to a document.\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m    preprocessed string\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lower:\n\u001b[0;32m---> 69\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m()\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m accent_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     71\u001b[0m     doc \u001b[38;5;241m=\u001b[39m accent_function(doc)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# utilities\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# plotting\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "# nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from nltk import word_tokenize,sent_tokenize\n",
    "#from nltk.tokenize import word_tokenize\n",
    "# sklearn\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Importing the dataset\n",
    "#DATASET_COLUMNS=['target','ids','date','flag','user','text']\n",
    "\n",
    "DATASET_ENCODING = \"ISO-8859-1\"\n",
    "#df = pd.read_csv('train.csv', encoding=DATASET_ENCODING, names=DATASET_COLUMNS)\n",
    "df = pd.read_csv('train.csv', encoding=DATASET_ENCODING)\n",
    "# Step - a : Remove blank rows if any.\n",
    "df['message'].dropna(inplace=True)\n",
    "\n",
    "df.sample(5)\n",
    "df.head()\n",
    "df.columns\n",
    "df. shape\n",
    "df.info()\n",
    "df.dtypes\n",
    "np.sum(df.isnull().any(axis=1))\n",
    "print('Count of columns in the data is:  ', len(df.columns))\n",
    "print('Count of rows in the data is:  ', len(df))\n",
    "\n",
    "\n",
    "df_test = pd.read_csv('test_with_no_labels.csv', encoding=DATASET_ENCODING)\n",
    "# Step - a : Remove blank rows if any.\n",
    "df_test['message'].dropna(inplace=True)\n",
    "\n",
    "\n",
    "#Check unique Target Values\n",
    "#df['target'].unique()\n",
    "df['sentiment'].unique()\n",
    "#Check the number of target values\n",
    "\n",
    "#df['target'].nunique()\n",
    "df['sentiment'].nunique()\n",
    "\n",
    "# Plotting the distribution for dataset.\n",
    "#ax = df.groupby('target').count().plot(kind='bar', title='Distribution of data',legend=False)\n",
    "#ax = df.groupby('sentiment').count().plot(kind='bar', title='Distribution of data',legend=False)\n",
    "#ax.set_xticklabels(['Negative','Positive'], rotation=0)\n",
    "\n",
    "\n",
    "\n",
    "# Storing data in lists.\n",
    "#text, sentiment = list(df['text']), list(df['target'])\n",
    "message, sentiment = list(df['message']), list(df['sentiment'])\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "#sns.countplot(x='target', data=df)\n",
    "sns.countplot(x='sentiment', data=df)\n",
    "\n",
    "#Selecting the text and Target column for our further analysis\n",
    "#data=df[['text','target']]\n",
    "data=df[['message','sentiment']]\n",
    "print(\"data\")\n",
    "print(data)\n",
    "data_test=df_test[['message']]\n",
    "print(\"data_test\")\n",
    "print(data_test)\n",
    "\n",
    "# Replacing the values to ease understanding. (Assigning 1 to Positive sentiment 4)\n",
    "\n",
    "#data['target'] = data['target'].replace(4,1)\n",
    "# Print unique values of target variables\n",
    "print(\"target unique values\")\n",
    "\n",
    "#data['target'].unique()\n",
    "print(data['sentiment'].unique())\n",
    "\n",
    "\n",
    "#Separating positive and negative tweets\n",
    "\n",
    "#data_pos = data[data['target'] == 1]\n",
    "#data_neg = data[data['target'] == 0]\n",
    "#taking one fourth data so we can run on our machine easily\n",
    "\n",
    "#data_pos = data_pos.iloc[:int(20000)]\n",
    "#data_neg = data_neg.iloc[:int(20000)]\n",
    "#Combining positive and negative tweets\n",
    "\n",
    "#dataset = pd.concat([data_pos, data_neg])\n",
    "# Making statement text in lower case\n",
    "\n",
    "#dataset['text']=dataset['text'].str.lower()\n",
    "#data['message']=data['message'].str.lower()\n",
    "data['message'] = [entry.lower() for entry in data['message']]\n",
    "\n",
    "print(\"before stop words\")\n",
    "print(data['message'].tail())\n",
    "\n",
    "#data_test['message']=data_test['message'].str.lower()\n",
    "data_test['message'] = [entry.lower() for entry in data_test['message']]\n",
    "print(\"before stop words test data\")\n",
    "print(data_test['message'].tail())\n",
    "\n",
    "\n",
    "stopwordlist = ['a', 'about', 'above', 'after', 'again', 'ain', 'all', 'am', 'an',\n",
    "             'and','any','are', 'as', 'at', 'be', 'because', 'been', 'before',\n",
    "             'being', 'below', 'between','both', 'by', 'can', 'd', 'did', 'do',\n",
    "             'does', 'doing', 'down', 'during', 'each','few', 'for', 'from',\n",
    "             'further', 'had', 'has', 'have', 'having', 'he', 'her', 'here',\n",
    "             'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in',\n",
    "             'into','is', 'it', 'its', 'itself', 'just', 'll', 'm', 'ma',\n",
    "             'me', 'more', 'most','my', 'myself', 'now', 'o', 'of', 'on', 'once',\n",
    "             'only', 'or', 'other', 'our', 'ours','ourselves', 'out', 'own', 're','s', 'same', 'she', \"shes\", 'should', \"shouldve\",'so', 'some', 'such',\n",
    "             't', 'than', 'that', \"thatll\", 'the', 'their', 'theirs', 'them',\n",
    "             'themselves', 'then', 'there', 'these', 'they', 'this', 'those',\n",
    "             'through', 'to', 'too','under', 'until', 'up', 've', 'very', 'was',\n",
    "             'we', 'were', 'what', 'when', 'where','which','while', 'who', 'whom',\n",
    "             'why', 'will', 'with', 'won', 'y', 'you', \"youd\",\"youll\", \"youre\",\n",
    "             \"youve\", 'your', 'yours', 'yourself', 'yourselves']\n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "#STOPWORDS = set(stopwordlist)\n",
    "#def cleaning_stopwords(text):\n",
    "#    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "#dataset['text'] = dataset['text'].apply(lambda text: cleaning_stopwords(text))\n",
    "#dataset['text'].head()\n",
    "\n",
    "\n",
    "STOPWORDS = set(stopwordlist)\n",
    "def cleaning_stopwords(message):\n",
    "    return \" \".join([word for word in str(message).split() if word not in STOPWORDS])\n",
    "data['message'] = data['message'].apply(lambda message: cleaning_stopwords(message))\n",
    "print(\"after stop words\")\n",
    "print(data['message'].head())\n",
    "data_test['message'] = data_test['message'].apply(lambda message: cleaning_stopwords(message))\n",
    "print(\"after stop words test data\")\n",
    "print(data_test['message'].head())\n",
    "\n",
    "\n",
    "\n",
    "#import string\n",
    "#english_punctuations = string.punctuation\n",
    "#punctuations_list = english_punctuations\n",
    "#def cleaning_punctuations(text):\n",
    "#    translator = str.maketrans('', '', punctuations_list)\n",
    "#    return text.translate(translator)\n",
    "#dataset['text']= dataset['text'].apply(lambda x: cleaning_punctuations(x))\n",
    "#dataset['text'].tail()   \n",
    "\n",
    "\n",
    "import string\n",
    "english_punctuations = string.punctuation\n",
    "punctuations_list = english_punctuations\n",
    "def cleaning_punctuations(message):\n",
    "    translator = str.maketrans('', '', punctuations_list)\n",
    "    return message.translate(translator)\n",
    "data['message']= data['message'].apply(lambda x: cleaning_punctuations(x))\n",
    "print(\"punctuation\")\n",
    "print(data['message'].tail())\n",
    "\n",
    "data_test['message']= data_test['message'].apply(lambda x: cleaning_punctuations(x))\n",
    "print(\"punctuation test data\")\n",
    "print(data_test['message'].tail())\n",
    "\n",
    "\n",
    "\n",
    "def cleaning_repeating_char(message):\n",
    "    return re.sub(r'(.)1+', r'1', message)\n",
    "data['message'] = data['message'].apply(lambda x: cleaning_repeating_char(x))\n",
    "print(\"after repeating charss\")\n",
    "print(data['message'].tail())\n",
    "\n",
    "data_test['message'] = data_test['message'].apply(lambda x: cleaning_repeating_char(x))\n",
    "print(\"after repeating chars test data\")\n",
    "print(data_test['message'].tail())\n",
    "\n",
    "\n",
    "\n",
    "def cleaning_URLs(data):\n",
    "    return re.sub('((www.[^s]+)|(https?://[^s]+))',' ',data)\n",
    "data['message'] = data['message'].apply(lambda x: cleaning_URLs(x))\n",
    "print(\"after clean urls\")\n",
    "print(data['message'].tail())\n",
    "\n",
    "data_test['message'] = data_test['message'].apply(lambda x: cleaning_URLs(x))\n",
    "print(\"after clean urls test data\")\n",
    "print(data_test['message'].tail())\n",
    "\n",
    "\n",
    "def cleaning_numbers(data):\n",
    "    return re.sub('[0-9]+', '', data)\n",
    "data['message'] = data['message'].apply(lambda x: cleaning_numbers(x))\n",
    "print(\"after clean numbers\")\n",
    "print(data['message'].tail())\n",
    "\n",
    "data_test['message'] = data_test['message'].apply(lambda x: cleaning_numbers(x))\n",
    "print(\"after clean numbers test data\")\n",
    "print(data_test['message'].tail())\n",
    "\n",
    "'''\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'w+')\n",
    "data['message'] = data['message'].apply(tokenizer.tokenize)\n",
    "print(\"after tokenize\")\n",
    "print(data['message'].tail())\n",
    "'''\n",
    "\n",
    "# Step - c : Tokenization : In this each entry in the corpus will be broken into set of words\n",
    "data['message']= [word_tokenize(entry) for entry in data['message']]\n",
    "data_test['message']= [word_tokenize(entry) for entry in data_test['message']]\n",
    "\n",
    "# Step - d : Remove Stop words, Non-Numeric and perfom Word Stemming/Lemmenting.\n",
    "# WordNetLemmatizer requires Pos tags to understand if the word is noun or verb or adjective etc. By default it is set to Noun\n",
    "tag_map = defaultdict(lambda : wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "for index,entry in enumerate(data['message']):\n",
    "    # Declaring Empty List to store the words that follow the rules for this step\n",
    "    Final_words = []\n",
    "    # Initializing WordNetLemmatizer()\n",
    "    word_Lemmatized = WordNetLemmatizer()\n",
    "    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
    "    for word, tag in pos_tag(entry):\n",
    "        # Below condition is to check for Stop words and consider only alphabets\n",
    "        if word not in stopwords.words('english') and word.isalpha():\n",
    "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
    "            Final_words.append(word_Final)\n",
    "    # The final processed set of words for each iteration will be stored in 'text_final'\n",
    "    data.loc[index,'text_final'] = str(Final_words)\n",
    "\n",
    "\n",
    "'''\n",
    "import nltk\n",
    "st = nltk.PorterStemmer()\n",
    "def stemming_on_text(data):\n",
    "    text = [st.stem(word) for word in data]\n",
    "    return data\n",
    "data['message']= data['message'].apply(lambda x: stemming_on_text(x))\n",
    "print(\"after porter stemmer\")\n",
    "print(data['message'].tail())\n",
    "\n",
    "data_test['message']= data_test['message'].apply(lambda x: stemming_on_text(x))\n",
    "print(\"after porter stemmer test data\")\n",
    "print(data_test['message'].tail())\n",
    "\n",
    "\n",
    "lm = nltk.WordNetLemmatizer()\n",
    "def lemmatizer_on_text(data):\n",
    "    text = [lm.lemmatize(word) for word in data]\n",
    "    return data\n",
    "data['message'] = data['message'].apply(lambda x: lemmatizer_on_text(x))\n",
    "print(\"after lemmatizer\")\n",
    "print(data['message'].tail())\n",
    "\n",
    "data_test['message'] = data_test['message'].apply(lambda x: lemmatizer_on_text(x))\n",
    "print(\"after lemmatizer test data\")\n",
    "print(data_test['message'].tail())\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X=data.message\n",
    "y=data.sentiment\n",
    "competion_test=data_test.message\n",
    "\n",
    "\n",
    "\n",
    "#data_neg = data['message'][:80000]\n",
    "#plt.figure(figsize = (20,20))\n",
    "#wc = WordCloud(max_words = 1000 , width = 1600 , height = 800,\n",
    "#               collocations=False).generate(\" \".join(data_neg))\n",
    "#plt.imshow(wc)\n",
    "\n",
    "\n",
    "\n",
    "#data_pos = data['text'][800000:]\n",
    "#wc = WordCloud(max_words = 1000 , width = 1600 , height = 800,\n",
    "#              collocations=False).generate(\" \".join(data_pos))\n",
    "#plt.figure(figsize = (20,20))\n",
    "#plt.imshow(wc)\n",
    "\n",
    "\n",
    "# Separating the 95% data for training data and 5% for testing data\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.05, random_state =42)\n",
    "\n",
    "\n",
    "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(data['text_final'],y,test_size=0.3)\n",
    "\n",
    "\n",
    "Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
    "Tfidf_vect.fit(data['text_final'])\n",
    "Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
    "Test_X_Tfidf = Tfidf_vect.transform(Test_X)\n",
    "\n",
    "\n",
    "print(Tfidf_vect.vocabulary_)\n",
    "\n",
    "print(Train_X_Tfidf)\n",
    "\n",
    "\n",
    "\n",
    "# fit the training dataset on the NB classifier\n",
    "Naive = naive_bayes.MultinomialNB()\n",
    "Naive.fit(Train_X_Tfidf,Train_Y)\n",
    "# predict the labels on validation dataset\n",
    "predictions_NB = Naive.predict(Test_X_Tfidf)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, Test_Y)*100)\n",
    "\n",
    "# Print the evaluation metrics for the dataset.\n",
    "print(classification_report(Test_Y, predictions_NB))\n",
    "\n",
    "\n",
    "\n",
    "# Classifier - Algorithm - SVM\n",
    "# fit the training dataset on the classifier\n",
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVM.fit(Train_X_Tfidf,Train_Y)\n",
    "# predict the labels on validation dataset\n",
    "predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, Test_Y)*100)\n",
    "\n",
    "# Print the evaluation metrics for the dataset.\n",
    "print(classification_report(Test_Y, predictions_SVM))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vectoriser = TfidfVectorizer(ngram_range=(1,2), max_features=500000)\n",
    "#vectoriser = TfidfVectorizer(ngram_range=(1,2), max_features=5000)\n",
    "vectoriser.fit(X_train)\n",
    "print('No. of feature_words: ', len(vectoriser.get_feature_names()))\n",
    "\n",
    "\n",
    "\n",
    "#obj = TfidfVectorizer()\n",
    "#corpus = ['This is sample document.', 'another random document.', 'third sample document text']\n",
    "#obj.fit_transform(X_train)\n",
    "print('X_train before vectoriser.transform X_train')\n",
    "print(X_train)\n",
    "\n",
    "X_train = vectoriser.transform(X_train)\n",
    "print('X_train after vectoriser.transform X_train')\n",
    "print(X_train)\n",
    "\n",
    "\n",
    "X_test  = vectoriser.transform(X_test)\n",
    "print('X_test after vectoriser.transform X_test')\n",
    "print(X_test)\n",
    "\n",
    "\n",
    "#Our sample from competition to predict on\n",
    "X_test_sample  = vectoriser.transform(competion_test)\n",
    "print('X_test_sample after vectoriser.transform data_test')\n",
    "print(X_test_sample)\n",
    "\n",
    "\n",
    "def model_Evaluate(model):\n",
    " # Predict values for Test dataset\n",
    " y_pred = model.predict(X_test)\n",
    " print(\"y predict\")\n",
    " print(y_pred)\n",
    " # Print the evaluation metrics for the dataset.\n",
    " print(classification_report(y_test, y_pred))\n",
    " # Compute and plot the Confusion matrix\n",
    " cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    " '''   \n",
    " categories = ['Negative','Positive']\n",
    " group_names = ['True Neg','False Pos', 'False Neg','True Pos']\n",
    " group_percentages = ['{0:.2%}'.format(value) for value in cf_matrix.flatten() / np.sum(cf_matrix)]\n",
    " labels = [f'{v1}n{v2}' for v1, v2 in zip(group_names,group_percentages)]\n",
    " labels = np.asarray(labels).reshape(2,2)\n",
    " sns.heatmap(cf_matrix, annot = labels, cmap = 'Blues',fmt = '',\n",
    " xticklabels = categories, yticklabels = categories)\n",
    " plt.xlabel(\"Predicted values\", fontdict = {'size':14}, labelpad = 10)\n",
    " plt.ylabel(\"Actual values\" , fontdict = {'size':14}, labelpad = 10)\n",
    " plt.title (\"Confusion Matrix\", fontdict = {'size':18}, pad = 20)\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "BNBmodel = BernoulliNB()\n",
    "BNBmodel.fit(X_train, y_train)\n",
    "print(\"score for BNB\")\n",
    "model_Evaluate(BNBmodel)\n",
    "y_pred1 = BNBmodel.predict(X_test)\n",
    "print(\"y predict1 BNB\")\n",
    "print(y_pred1)\n",
    "\n",
    "'''\n",
    "y_pred_final = BNBmodel.predict(X_test_sample)\n",
    "print(\"y predict final\")\n",
    "print(y_pred_final)\n",
    "\n",
    "np.savetxt(\"output.csv\", y_pred_final, delimiter=\",\")\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred1)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=1, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC CURVE')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "'''\n",
    "\n",
    "\n",
    "SVCmodel = LinearSVC()\n",
    "\n",
    "SVCmodel.fit(X_train, y_train)\n",
    "print(\"score for svc\")\n",
    "model_Evaluate(SVCmodel)\n",
    "\n",
    "y_pred2 = SVCmodel.predict(X_test)\n",
    "\n",
    "'''\n",
    "y_pred_final = SVCmodel.predict(X_test_sample)\n",
    "print(\"y predict final\")\n",
    "print(y_pred_final)\n",
    "\n",
    "np.savetxt(\"outputsvc.csv\", y_pred_final, delimiter=\",\")\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred2)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=1, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC CURVE')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "'''\n",
    "\n",
    "\n",
    "LRmodel = LogisticRegression(C = 2, max_iter = 1000, n_jobs=-1)\n",
    "LRmodel.fit(X_train, y_train)\n",
    "print(\"score for LRmodel\")\n",
    "model_Evaluate(LRmodel)\n",
    "y_pred3 = LRmodel.predict(X_test)\n",
    "\n",
    "y_pred_final = LRmodel.predict(X_test_sample)\n",
    "print(\"y predict final\")\n",
    "print(y_pred_final)\n",
    "\n",
    "np.savetxt(\"outputslr.csv\", y_pred_final, delimiter=\",\")\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred3)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=1, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC CURVE')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'urllib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/Explore-AI/Public-Data/master/Data/classification_sprint//alice_in_wonderland.txt\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mISO-8859-1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mprint_some_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(data[:\u001b[38;5;241m863\u001b[39m])\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mprint_some_url\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_some_url\u001b[39m():\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/Explore-AI/Public-Data/master/Data/classification_sprint//alice_in_wonderland.txt\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mISO-8859-1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'urllib' is not defined"
     ]
    }
   ],
   "source": [
    "# read in the data\n",
    "def print_some_url():\n",
    "    with urllib.request.urlopen('https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Data/classification_sprint//alice_in_wonderland.txt') as f:\n",
    "        return f.read().decode('ISO-8859-1')\n",
    "\n",
    "data = print_some_url()\n",
    "print(data[:863])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to lowercase and remove punctuation  \n",
    "\n",
    "Do not change or remove any of the code in these cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bevan/.local/lib/python3.8/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.18.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "def remove_punctuation(words):\n",
    "    words = words.lower()\n",
    "    return ''.join([x for x in words if x not in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = remove_punctuation(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a bag of words and assigning our stemmer and lemmatizer\n",
    "\n",
    "Pay special attention to what these functions return and how the subsequent texts and lists look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define stemmer function\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "# tokenise data\n",
    "tokeniser = TreebankWordTokenizer()\n",
    "tokens = tokeniser.tokenize(data)\n",
    "\n",
    "# define lemmatiser\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# bag of words\n",
    "def bag_of_words_count(words, word_dict={}):\n",
    "    \"\"\" this function takes in a list of words and returns a dictionary \n",
    "        with each word as a key, and the value represents the number of \n",
    "        times that word appeared\"\"\"\n",
    "    for word in words:\n",
    "        if word in word_dict.keys():\n",
    "            word_dict[word] += 1\n",
    "        else:\n",
    "            word_dict[word] = 1\n",
    "    return word_dict\n",
    "\n",
    "# remove stopwords\n",
    "tokens_less_stopwords = [word for word in tokens if word not in stopwords.words('english')]\n",
    "\n",
    "# create bag of words\n",
    "bag_of_words = bag_of_words_count(tokens_less_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the stemmer and lemmatizer functions (defined in the cells above) from the relevant library to find the stem and lemma of the nth word in the token list.\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take a `list` as input and return a  `dict` type as output.\n",
    "* The dictionary should have the keys **'original',  'stem' and 'lemma'** with the corresponding values being the nth word transformed in that way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "\n",
    "def find_roots(token_list, n):\n",
    "    # your code here\n",
    "    token = token_list[n-1]\n",
    "    \n",
    "    stem = stemmer.stem(token)\n",
    "    lemma = lemmatizer.lemmatize(token)\n",
    "    return {\"original\": token, \"stem\": stem, \"lemma\": lemma}\n",
    "\n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'original': 'daisies', 'stem': 'daisi', 'lemma': 'daisy'}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_roots(tokens, 120) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Expected Outputs:**_\n",
    "```python\n",
    "find_roots(tokens, 120) == \n",
    "{'original': 'daisies', \n",
    "'stem': 'daisi', \n",
    "'lemma': 'daisy'}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many stopwords are in the text in total?   \n",
    "\n",
    "_Hint_ : you can use the nltk stopwords dictionary \n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Function should take a `list` as input \n",
    "* The number of stopwords should be returned as an `int` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION \n",
    "def count_stopwords(token_list):\n",
    "    # your code here\n",
    " \n",
    "  \n",
    "    stop_words = set(stopwords.words('english'))  \n",
    "     \n",
    "    filtered_sentence = [w for w in token_list if not w.lower() in stop_words]\n",
    "  \n",
    "    filtered_sentence = []\n",
    "    total = 0\n",
    "  \n",
    "    for w in token_list:\n",
    "        if w in stop_words:\n",
    "            filtered_sentence.append(w)\n",
    "            total = total + 1 \n",
    "        \n",
    "    \n",
    "    \n",
    "    return int(total)\n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13774"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_stopwords(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Expected output:**_\n",
    "\n",
    "```python\n",
    "count_stopwords(tokens) == 13774\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "How many **unique** words are in the text?\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Function should take a `list` as input and return an `int` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def unique_words(token_list):\n",
    "    # your code here\n",
    "\n",
    "\n",
    "    count = {}\n",
    "    for w in token_list:\n",
    "      if w in count:\n",
    "        count[w] += 1\n",
    "      else:\n",
    "        count[w] = 1\n",
    "  \n",
    "        \n",
    "    total = 0    \n",
    "    for word, times in count.items():\n",
    "        \n",
    "      \n",
    "      total = total + 1\n",
    "     \n",
    "    \n",
    "    return int(total)\n",
    "\n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2749"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Expected output:**_\n",
    "\n",
    "```python\n",
    "unique_words(tokens) == 2749\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the kth most frequently occuring word in the bag of words?\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Function should take a `dict` and an `int` k as input\n",
    "* Function should return the kth most common word as a `str`\n",
    "\n",
    "_Hint : bag_of_words already does not include stopwords_\n",
    "\n",
    "Example: \n",
    "```python\n",
    "most_common_word(bag = {'apple': 30, 'orange': 12, 'pear': 50, 'banana': 12}, 2)\n",
    "\n",
    ">>> 'apple'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def most_common_word(bag, k):  \n",
    "  \n",
    "\n",
    "    from collections import Counter\n",
    "\n",
    "    mostcom = Counter(bag).most_common(k)\n",
    "\n",
    "    first_element = mostcom[-1]\n",
    "    res = [first_element[0]] \n",
    "    res2 = ''.join(res)\n",
    "    \n",
    "\n",
    "    return res2\n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'little'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common_word(bag_of_words, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Expected output:**_\n",
    "\n",
    "```python\n",
    "most_common_word(bag_of_words, 3) == 'little'\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "How many words appear n times in the text?\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Input is taken as a `dict` and an `int` n, where n is the number of times the word appears in the text\n",
    "* Count the number of words that appear n times in the text\n",
    "* Output should be the count as an `int`\n",
    "\n",
    "Example: \n",
    "```python\n",
    "word_frequency_count(bag = {'apple': 30, 'orange': 12, 'pear': 50, 'banana': 12}, 12)\n",
    "\n",
    ">>> 2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "\n",
    "def word_frequency_count(bag, n):\n",
    "    # your code here\n",
    "   \n",
    "    total = sum(v for k,v in bag.items() if v == n)\n",
    "    total_divide_by_n = total/n\n",
    "    \n",
    "    return int(total_divide_by_n)   \n",
    "   \n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequency_count(bag_of_words, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequency_count(bag_of_words, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Expected output:**_\n",
    "\n",
    "```python\n",
    "most_common_word(bag_of_words, 5) == 97\n",
    "most_common_word(bag_of_words, 8) == 49\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
